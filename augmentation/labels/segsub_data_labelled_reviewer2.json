[
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30171458,
            "webqa/object_perturbation/30136057_d5bf82c80dba11ecb1e81171463288e9_97.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Borthwick Castle, Interior 07\n<image>\nCaption: 2016 Severndroog Castle, interior 04\nQ: \"What colors are found on the chairs in the Borthwick Castle?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf82c80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30009487,
            "webqa/object_perturbation/30143140_d5bd99860dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Torch 2012 at Jodrell Bank 1\n<image>\nCaption: 2008 Olympic Torch Relay, London AB3\nQ: \"What color appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bd99860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30329762_d5c7f7280dba11ecb1e81171463288e9_70.jpeg",
            30032281
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Tokyo Dome side view\n<image>\nCaption: Tokyo Dome 20130907\nQ: \"What colors can the exterior light emit from the Tokyo dome?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c7f7280dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30256866_d5c306460dba11ecb1e81171463288e9_82.jpeg",
            30370544
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: John's Inc Fresno\n<image>\nCaption: Burger King Restaurant in Sherman Oaks, California - panoramio\nQ: \"What colors are found on both the sign for Burger King Restaurant in Sherman Oaks, California and the sign for John's Inc in Fresno?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c306460dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30327092,
            "webqa/object_perturbation/30338343_d5c2af200dba11ecb1e81171463288e9_85.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Club 33 2013 11\n<image>\nCaption: Club 33 Dining Room 2013\nQ: \"What color are the tablecloths in Club 33 at Disneyland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2af200dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30142352,
            "webqa/object_perturbation/30305558_d5c0af5e0dba11ecb1e81171463288e9_51.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: KFC, North End Road, Fulham, London 01\n<image>\nCaption: Chicken Cottage, North End Road, Fulham, London 01\nQ: \"What color is the background of the KFC restaurant and Chicken Cottage restaurant sign?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c0af5e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30343387,
            "webqa/object_perturbation/30053690_d5bf5f140dba11ecb1e81171463288e9_89.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Holy Trinity Church, Twickenham - London. (6256347665)\n<image>\nCaption: All Hallows Parish Church in Twickenham\nQ: \"What shape are the largest towers at All Hallows Parish Church and Holy Trinity Church in Twickenham?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf5f140dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_40.jpeg",
            30237804
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30076718,
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30009487_d5bd99860dba11ecb1e81171463288e9_76.jpeg",
            30143140
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Torch 2012 at Jodrell Bank 1\n<image>\nCaption: 2008 Olympic Torch Relay, London AB3\nQ: \"What color appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bd99860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30009487,
            "webqa/object_perturbation/30143140_d5bd99860dba11ecb1e81171463288e9_69.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Torch 2012 at Jodrell Bank 1\n<image>\nCaption: 2008 Olympic Torch Relay, London AB3\nQ: \"What color appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bd99860dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_68.jpeg",
            30237804
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30327092_d5c2af200dba11ecb1e81171463288e9_38.jpeg",
            30338343
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Club 33 2013 11\n<image>\nCaption: Club 33 Dining Room 2013\nQ: \"What color are the tablecloths in Club 33 at Disneyland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2af200dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30193626,
            "webqa/object_perturbation/30355132_d5c2f55c0dba11ecb1e81171463288e9_63.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arriva bus VXE724 (YJ11 TVE), 11 August 2013\n<image>\nCaption: Sights and sightseers - geograph.org.uk - 1903726\nQ: \"What colors are on both the The Original Tour bus and the Tower bridge in London?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2f55c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30050059,
            "webqa/object_perturbation/30084499_d5cd51b40dba11ecb1e81171463288e9_51.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Dublin zoo Orangutang 2011\n<image>\nCaption: Alouatta guariba\nQ: \"What color are the coats of both the Orangutang and the Howler Monkey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cd51b40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30009487,
            "webqa/object_perturbation/30143140_d5bd99860dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Torch 2012 at Jodrell Bank 1\n<image>\nCaption: 2008 Olympic Torch Relay, London AB3\nQ: \"What color appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bd99860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30177807,
            "webqa/object_perturbation/30145245_d5c273340dba11ecb1e81171463288e9_89.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Lamborghini Veneno (11225271396)\n<image>\nCaption: 1954 Maserati A6 GCS\nQ: \"What color is both the primary body paint color off the 1954 Maserati A6 GCS and is also present on the wheels of the Lamborghini Veneno?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c273340dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30327560,
            "webqa/object_perturbation/30309162_d5c533d00dba11ecb1e81171463288e9_95.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Beijing Qianmen 2008\n<image>\nCaption: Beijing Daxing International Airport 12\nQ: \"What color on the ceiling of Beijing Daxing International Airport is the same as the color used to illuminate signs above Qianmen, Beijing ?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c533d00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30327092,
            "webqa/object_perturbation/30338343_d5c2af200dba11ecb1e81171463288e9_59.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Club 33 2013 11\n<image>\nCaption: Club 33 Dining Room 2013\nQ: \"What color are the tablecloths in Club 33 at Disneyland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2af200dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30074316,
            "webqa/object_perturbation/30044834_d5c5a5220dba11ecb1e81171463288e9_87.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Berlin Cathedral 01\n<image>\nCaption: Schloss Charlottenburg Berlin 2007\nQ: \"What colors do the roof domes Schloss Charlottenburg in Berlin and the Berlin Cathedral share?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c5a5220dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30329762,
            "webqa/object_perturbation/30032281_d5c7f7280dba11ecb1e81171463288e9_97.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Tokyo Dome side view\n<image>\nCaption: Tokyo Dome 20130907\nQ: \"What colors can the exterior light emit from the Tokyo dome?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c7f7280dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30132486,
            "webqa/object_perturbation/30290492_d5bcadbe0dba11ecb1e81171463288e9_67.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: HK Soho Central 22 Elgin Street Tree furniture shop CNC Fashion Oct-2012\n<image>\nCaption: HK Central Soho night Staunton Street restaurant Brivo Pizza Pasta & Grill Apr-2013\nQ: \"Which colors are found on the sign for both Brivo Pizza Pasta & Grill and the 22 Elgin Street Tree furniture shop?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bcadbe0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30343650,
            "webqa/object_perturbation/30105538_d5c13d840dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Poland's Pavillion at the 2010 World Expo in Shanghai\n<image>\nCaption: Estonia Pavillion at 2010 Shanghai Expo\nQ: \"Which color is found on both the Estonia and Poland Pavilion at Expo 2010?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c13d840dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30076718,
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30267171,
            "webqa/object_perturbation/30146139_d5ca08ec0dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: HK Sheung Wan Soho \u58eb\u4e39\u9813\u8857 48-50 Staunton Street \u5049\u767c\u6a13 Wai Fat Building clothing shop removal sale Jan-2012\n<image>\nCaption: HK Central shop Soho Spy Henry Au \u58eb\u4e39\u9813\u8857 Staunton Street clothing shop Jan-2012\nQ: \"Which color is found on the sign for both Spy Henry Au and Wai Fat Building clothing shop removal sale?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5ca08ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30028543_d5c12c540dba11ecb1e81171463288e9_98.jpeg",
            30239433
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: HP Centre Edmonton Alberta Canada 01A\n<image>\nCaption: Northern Alberta Jubilee Auditorium Edmonton Alberta Canada 01A\nQ: \"What shape is the front of both the Northern Alberta Jubilee Auditorium and the HP Centre in Edmonton Alberta?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c12c540dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30356487,
            "webqa/object_perturbation/30236734_d5c2924c0dba11ecb1e81171463288e9_25.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Nydia-3, Randolph Rogers\n<image>\nCaption: Jean-Antoine Houdon-La frileuse\nQ: \"What shape is the base of both the sculpture of Nydia the Blind Flower Girl of Pompeii at the University of Michigan and the sculpture \"La frileuse\"?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2924c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30057678,
            "webqa/object_perturbation/30141396_d5c9ecc20dba11ecb1e81171463288e9_87.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Meidan Emam, Esfahan-130683\n<image>\nCaption: Entrace to Imam (Shah) Mosque, Esfahan, Iran (14471624621)\nQ: \"What color is featured in Interior of the Sheikh Lotfollah Mosque, Meidan Emam, Esfahan that isn't in the Entrance to Imam (Shah) Mosque, Esfahan, Iran?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c9ecc20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_64.jpeg",
            30237804
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30318730,
            "webqa/object_perturbation/30287563_d5c3b7620dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Closed playground in New York City on April 1st, 2020\n<image>\nCaption: Central Park tent hospital (1) jeh\nQ: \"What color are the tents while the sign indicates that the playground is what?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c3b7620dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_84.jpeg",
            30237804
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30064532,
            "webqa/object_perturbation/30269457_d5cb25c40dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 01\n<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 02\nQ: \"What color are the ceilings in the Grand Bazaar in Istanbul?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cb25c40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30267171,
            "webqa/object_perturbation/30146139_d5ca08ec0dba11ecb1e81171463288e9_53.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: HK Sheung Wan Soho \u58eb\u4e39\u9813\u8857 48-50 Staunton Street \u5049\u767c\u6a13 Wai Fat Building clothing shop removal sale Jan-2012\n<image>\nCaption: HK Central shop Soho Spy Henry Au \u58eb\u4e39\u9813\u8857 Staunton Street clothing shop Jan-2012\nQ: \"Which color is found on the sign for both Spy Henry Au and Wai Fat Building clothing shop removal sale?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5ca08ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30365032,
            "webqa/object_perturbation/30367480_d5c334860dba11ecb1e81171463288e9_91.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Eiffel Tower Las Vegas 30MAR19\n<image>\nCaption: THE PARIS (VEGAS)\nQ: \"The Eifel Tower at Paris Las Vegas is lighted with what color lights at night?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c334860dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30016255,
            "webqa/object_perturbation/30112308_d5bdb11e0dba11ecb1e81171463288e9_61.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Buildwas Abbey Chapter House roof - geograph.org.uk - 1311471\n<image>\nCaption: London - Westminster abbey - chapter house 04\nQ: \"What color are the bricks nearest the ground in Buildwas Abbey Chapter House roof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bdb11e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066686,
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30169184,
            "webqa/object_perturbation/30082448_d5bfec900dba11ecb1e81171463288e9_59.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Ulysses Butterfly - melbourne zoo\n<image>\nCaption: Aberrated Silverline butterfly, perhaps Cigaritis vulcanus\nQ: \"What are the colors of an Aberrated Silverline and the Ulysses Butterfly?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bfec900dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30033583_d5c3abbe0dba11ecb1e81171463288e9_92.jpeg",
            30303600
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Grocery Oysters (45911798714)\n<image>\nCaption: Parkway Mall - Metro\nQ: \"Which colors are on both the sign on the Metro at Parkway Mall and a box of Uncle Willy's standard shape oysters?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c3abbe0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30173409,
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_67.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066773,
            "webqa/object_perturbation/30148061_d5c83e040dba11ecb1e81171463288e9_95.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry Las Vegas\nQ: \"Which color is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c83e040dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30064532,
            "webqa/object_perturbation/30269457_d5cb25c40dba11ecb1e81171463288e9_63.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 01\n<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 02\nQ: \"What color are the ceilings in the Grand Bazaar in Istanbul?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cb25c40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30177807,
            "webqa/object_perturbation/30145245_d5c273340dba11ecb1e81171463288e9_51.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Lamborghini Veneno (11225271396)\n<image>\nCaption: 1954 Maserati A6 GCS\nQ: \"What color is both the primary body paint color off the 1954 Maserati A6 GCS and is also present on the wheels of the Lamborghini Veneno?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c273340dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30204008_d5be885a0dba11ecb1e81171463288e9_78.jpeg",
            30037672
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: AstrophytumMyriostigma\n<image>\nCaption: Wild ginger lily from Mt. Kemiri, Aceh (8188214956)\nQ: \"What color do the Astrophytum Myriostigma and Wild Ginger Lily share?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5be885a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30016255,
            "webqa/object_perturbation/30112308_d5bdb11e0dba11ecb1e81171463288e9_75.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Buildwas Abbey Chapter House roof - geograph.org.uk - 1311471\n<image>\nCaption: London - Westminster abbey - chapter house 04\nQ: \"What color are the bricks nearest the ground in Buildwas Abbey Chapter House roof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bdb11e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30193626,
            "webqa/object_perturbation/30355132_d5c2f55c0dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arriva bus VXE724 (YJ11 TVE), 11 August 2013\n<image>\nCaption: Sights and sightseers - geograph.org.uk - 1903726\nQ: \"What colors are on both the The Original Tour bus and the Tower bridge in London?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2f55c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066773_d5c83e040dba11ecb1e81171463288e9_74.jpeg",
            30148061
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry Las Vegas\nQ: \"Which color is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c83e040dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30173409,
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_75.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30343387_d5bf5f140dba11ecb1e81171463288e9_32.jpeg",
            30053690
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Holy Trinity Church, Twickenham - London. (6256347665)\n<image>\nCaption: All Hallows Parish Church in Twickenham\nQ: \"What shape are the largest towers at All Hallows Parish Church and Holy Trinity Church in Twickenham?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf5f140dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30284522_d5c5efdc0dba11ecb1e81171463288e9_96.jpeg",
            30336668
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Deutsches Museum 1\n<image>\nCaption: Bayerisches Nationalmuseum - Muenchen - 2013\nQ: \"What color do the Deutsches museum in Munich, Germany and the  Bayerisches Nationalmuseum share on their rounded rooftops?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c5efdc0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30064532,
            "webqa/object_perturbation/30269457_d5cb25c40dba11ecb1e81171463288e9_83.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 01\n<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 02\nQ: \"What color are the ceilings in the Grand Bazaar in Istanbul?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cb25c40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30343650_d5c13d840dba11ecb1e81171463288e9_66.jpeg",
            30105538
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Poland's Pavillion at the 2010 World Expo in Shanghai\n<image>\nCaption: Estonia Pavillion at 2010 Shanghai Expo\nQ: \"Which color is found on both the Estonia and Poland Pavilion at Expo 2010?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c13d840dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30033583_d5c3abbe0dba11ecb1e81171463288e9_36.jpeg",
            30303600
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Grocery Oysters (45911798714)\n<image>\nCaption: Parkway Mall - Metro\nQ: \"Which colors are on both the sign on the Metro at Parkway Mall and a box of Uncle Willy's standard shape oysters?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c3abbe0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30064532,
            "webqa/object_perturbation/30269457_d5cb25c40dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 01\n<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 02\nQ: \"What color are the ceilings in the Grand Bazaar in Istanbul?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cb25c40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30235034,
            "webqa/object_perturbation/30045971_d5c287020dba11ecb1e81171463288e9_71.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\n<image>\nCaption: Chulalongkorns paviljong\nQ: \"What color is the roof of both the pavilion of Chulalongkorn south of Bispg\u00e5rden, Sweden and the Thai Pavilion at the National Museum in Bangkok?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c287020dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30085562_d5c7c7e40dba11ecb1e81171463288e9_30.jpeg",
            30346828
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2018-06-28 10 16 31 View west along Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, Warren County, New Jersey\n<image>\nCaption: 2018-06-28 09 37 51 View east along Interstate 80 just east of Exit 12 in Hope Township, Warren County, New Jersey\nQ: \"What color are the letterings of the road signs to the right of the Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, and to the right of Interstate 80 just east of Exit 12 in Hope Township?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c7c7e40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30173409,
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_33.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30168219_d5c190400dba11ecb1e81171463288e9_88.jpeg",
            30113021
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Malmo-TurningTorso2005August15\n<image>\nCaption: Bangkok Baiyoke Tower\nQ: \"What shape is at the top of both the Baiyoke Tower and the Turning Torso skyscraper?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c190400dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30343650,
            "webqa/object_perturbation/30105538_d5c13d840dba11ecb1e81171463288e9_69.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Poland's Pavillion at the 2010 World Expo in Shanghai\n<image>\nCaption: Estonia Pavillion at 2010 Shanghai Expo\nQ: \"Which color is found on both the Estonia and Poland Pavilion at Expo 2010?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c13d840dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066686,
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_59.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30318730,
            "webqa/object_perturbation/30287563_d5c3b7620dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Closed playground in New York City on April 1st, 2020\n<image>\nCaption: Central Park tent hospital (1) jeh\nQ: \"What color are the tents while the sign indicates that the playground is what?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c3b7620dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30085562_d5c7c7e40dba11ecb1e81171463288e9_78.jpeg",
            30346828
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2018-06-28 10 16 31 View west along Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, Warren County, New Jersey\n<image>\nCaption: 2018-06-28 09 37 51 View east along Interstate 80 just east of Exit 12 in Hope Township, Warren County, New Jersey\nQ: \"What color are the letterings of the road signs to the right of the Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, and to the right of Interstate 80 just east of Exit 12 in Hope Township?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c7c7e40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30327092_d5c2af200dba11ecb1e81171463288e9_50.jpeg",
            30338343
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Club 33 2013 11\n<image>\nCaption: Club 33 Dining Room 2013\nQ: \"What color are the tablecloths in Club 33 at Disneyland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2af200dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30057678,
            "webqa/object_perturbation/30141396_d5c9ecc20dba11ecb1e81171463288e9_25.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Meidan Emam, Esfahan-130683\n<image>\nCaption: Entrace to Imam (Shah) Mosque, Esfahan, Iran (14471624621)\nQ: \"What color is featured in Interior of the Sheikh Lotfollah Mosque, Meidan Emam, Esfahan that isn't in the Entrance to Imam (Shah) Mosque, Esfahan, Iran?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c9ecc20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30345508,
            "webqa/object_perturbation/30252740_d5be01a00dba11ecb1e81171463288e9_87.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Aster-amellus-flower\n<image>\nCaption: Wood Anemone (Anemone nemorosa)\nQ: \"What color is the center of both the Aster amellus and the Wood Anemone?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5be01a00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30193626,
            "webqa/object_perturbation/30355132_d5c2f55c0dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arriva bus VXE724 (YJ11 TVE), 11 August 2013\n<image>\nCaption: Sights and sightseers - geograph.org.uk - 1903726\nQ: \"What colors are on both the The Original Tour bus and the Tower bridge in London?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c2f55c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30163499,
            "webqa/object_perturbation/30235034_d5c9aa820dba11ecb1e81171463288e9_55.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: The Royal Sala Thai, University of Hawaii at Manoa\n<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\nQ: \"What color is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c9aa820dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30337052,
            "webqa/object_perturbation/30088225_d5c497180dba11ecb1e81171463288e9_75.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: EMG office building, 2018 Sashalom\n<image>\nCaption: Knoxville Building Office LBMC\nQ: \"Which colors are found on both the Knoxville Building Office LBMC and the EMG office building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c497180dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30085562,
            "webqa/object_perturbation/30346828_d5c7c7e40dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2018-06-28 10 16 31 View west along Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, Warren County, New Jersey\n<image>\nCaption: 2018-06-28 09 37 51 View east along Interstate 80 just east of Exit 12 in Hope Township, Warren County, New Jersey\nQ: \"What color are the letterings of the road signs to the right of the Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, and to the right of Interstate 80 just east of Exit 12 in Hope Township?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c7c7e40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30204008,
            "webqa/object_perturbation/30037672_d5be885a0dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: AstrophytumMyriostigma\n<image>\nCaption: Wild ginger lily from Mt. Kemiri, Aceh (8188214956)\nQ: \"What color do the Astrophytum Myriostigma and Wild Ginger Lily share?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5be885a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30235034,
            "webqa/object_perturbation/30045971_d5c287020dba11ecb1e81171463288e9_79.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\n<image>\nCaption: Chulalongkorns paviljong\nQ: \"What color is the roof of both the pavilion of Chulalongkorn south of Bispg\u00e5rden, Sweden and the Thai Pavilion at the National Museum in Bangkok?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c287020dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30163499,
            "webqa/object_perturbation/30235034_d5c9aa820dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: The Royal Sala Thai, University of Hawaii at Manoa\n<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\nQ: \"What color is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c9aa820dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30235034_d5c287020dba11ecb1e81171463288e9_84.jpeg",
            30045971
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\n<image>\nCaption: Chulalongkorns paviljong\nQ: \"What color is the roof of both the pavilion of Chulalongkorn south of Bispg\u00e5rden, Sweden and the Thai Pavilion at the National Museum in Bangkok?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c287020dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066773,
            "webqa/object_perturbation/30324476_d5cd33640dba11ecb1e81171463288e9_97.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry buildings Duesseldorf Neuer Zollhof 2 Unterbilk Duesseldorf Germany 01\nQ: \"Which color is found on both MIT Building 32 and Neuer Zollhof no. 2?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cd33640dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30337052,
            "webqa/object_perturbation/30088225_d5c497180dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: EMG office building, 2018 Sashalom\n<image>\nCaption: Knoxville Building Office LBMC\nQ: \"Which colors are found on both the Knoxville Building Office LBMC and the EMG office building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c497180dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066686,
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30142352,
            "webqa/object_perturbation/30305558_d5c0af5e0dba11ecb1e81171463288e9_67.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: KFC, North End Road, Fulham, London 01\n<image>\nCaption: Chicken Cottage, North End Road, Fulham, London 01\nQ: \"What color is the background of the KFC restaurant and Chicken Cottage restaurant sign?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c0af5e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30365032,
            "webqa/object_perturbation/30367480_d5c334860dba11ecb1e81171463288e9_93.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Eiffel Tower Las Vegas 30MAR19\n<image>\nCaption: THE PARIS (VEGAS)\nQ: \"The Eifel Tower at Paris Las Vegas is lighted with what color lights at night?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c334860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30256866,
            "webqa/object_perturbation/30370544_d5c306460dba11ecb1e81171463288e9_99.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: John's Inc Fresno\n<image>\nCaption: Burger King Restaurant in Sherman Oaks, California - panoramio\nQ: \"What colors are found on both the sign for Burger King Restaurant in Sherman Oaks, California and the sign for John's Inc in Fresno?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c306460dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30365032_d5c334860dba11ecb1e81171463288e9_82.jpeg",
            30367480
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Eiffel Tower Las Vegas 30MAR19\n<image>\nCaption: THE PARIS (VEGAS)\nQ: \"The Eifel Tower at Paris Las Vegas is lighted with what color lights at night?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c334860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30076718,
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_69.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30337052,
            "webqa/object_perturbation/30088225_d5c497180dba11ecb1e81171463288e9_67.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: EMG office building, 2018 Sashalom\n<image>\nCaption: Knoxville Building Office LBMC\nQ: \"Which colors are found on both the Knoxville Building Office LBMC and the EMG office building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c497180dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30064532,
            "webqa/object_perturbation/30269457_d5cb25c40dba11ecb1e81171463288e9_65.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 01\n<image>\nCaption: 2013-01-02 Grand Bazaar, Istanbul 02\nQ: \"What color are the ceilings in the Grand Bazaar in Istanbul?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cb25c40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30142352_d5c0af5e0dba11ecb1e81171463288e9_44.jpeg",
            30305558
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: KFC, North End Road, Fulham, London 01\n<image>\nCaption: Chicken Cottage, North End Road, Fulham, London 01\nQ: \"What color is the background of the KFC restaurant and Chicken Cottage restaurant sign?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c0af5e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30050059,
            "webqa/object_perturbation/30084499_d5cd51b40dba11ecb1e81171463288e9_81.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Dublin zoo Orangutang 2011\n<image>\nCaption: Alouatta guariba\nQ: \"What color are the coats of both the Orangutang and the Howler Monkey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cd51b40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066773,
            "webqa/object_perturbation/30324476_d5cd33640dba11ecb1e81171463288e9_67.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry buildings Duesseldorf Neuer Zollhof 2 Unterbilk Duesseldorf Germany 01\nQ: \"Which color is found on both MIT Building 32 and Neuer Zollhof no. 2?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5cd33640dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_58.jpeg",
            30237804
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30016255,
            "webqa/object_perturbation/30112308_d5bdb11e0dba11ecb1e81171463288e9_81.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Buildwas Abbey Chapter House roof - geograph.org.uk - 1311471\n<image>\nCaption: London - Westminster abbey - chapter house 04\nQ: \"What color are the bricks nearest the ground in Buildwas Abbey Chapter House roof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bdb11e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30171458,
            "webqa/object_perturbation/30136057_d5bf82c80dba11ecb1e81171463288e9_85.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Borthwick Castle, Interior 07\n<image>\nCaption: 2016 Severndroog Castle, interior 04\nQ: \"What colors are found on the chairs in the Borthwick Castle?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bf82c80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30028543_d5c12c540dba11ecb1e81171463288e9_74.jpeg",
            30239433
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: HP Centre Edmonton Alberta Canada 01A\n<image>\nCaption: Northern Alberta Jubilee Auditorium Edmonton Alberta Canada 01A\nQ: \"What shape is the front of both the Northern Alberta Jubilee Auditorium and the HP Centre in Edmonton Alberta?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c12c540dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30343650,
            "webqa/object_perturbation/30105538_d5c13d840dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Poland's Pavillion at the 2010 World Expo in Shanghai\n<image>\nCaption: Estonia Pavillion at 2010 Shanghai Expo\nQ: \"Which color is found on both the Estonia and Poland Pavilion at Expo 2010?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c13d840dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30152316_d5be28240dba11ecb1e81171463288e9_90.jpeg",
            30189126
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Muchom\u016frka \u010derven\u00e1\n<image>\nCaption: Clathrus archeri BW 1\nQ: \"What color does the Clathrus archeri and Muchom\u016frka \u010derven\u00e1 share?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5be28240dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30217290_d5c41a0e0dba11ecb1e81171463288e9_36.jpeg",
            30156181
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Swann Fountain North2\n<image>\nCaption: Swann Fountain\nQ: \"What is the color of the sculptures in Swann Fountain?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c41a0e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30318730,
            "webqa/object_perturbation/30287563_d5c3b7620dba11ecb1e81171463288e9_53.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Closed playground in New York City on April 1st, 2020\n<image>\nCaption: Central Park tent hospital (1) jeh\nQ: \"What color are the tents while the sign indicates that the playground is what?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c3b7620dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066686,
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_85.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30286938,
            "webqa/object_perturbation/30358295_d5c308d00dba11ecb1e81171463288e9_59.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Oak Cliff September 2016 28 (Taqueria Pedrito and Las Ranitas)\n<image>\nCaption: Chilis dallas\nQ: \"What colors are both on the sign for Chili's in Dallas and on the sign for Taqueria Pedrito in the Oak Cliff neighborhood in Dallas?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c308d00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30029681_d5bd8c5c0dba11ecb1e81171463288e9_26.jpeg",
            30174026
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Admiral casino, King Street, Hammersmith\n<image>\nCaption: Paddy Power, King Street, Hammersmith 02\nQ: \"What color is the lettering on the sign at Paddy Power and the Admiral casino?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bd8c5c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30329910,
            "webqa/object_perturbation/30225071_d5bfec400dba11ecb1e81171463288e9_69.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Snowy plover\n<image>\nCaption: Wood Warbler - Pantelleria - Italy 3521 (19079866170) (2)\nQ: \"What color is the underside of both the Snowy plover and the Wood Warbler?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5bfec400dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30066773,
            "webqa/object_perturbation/30148061_d5c83e040dba11ecb1e81171463288e9_97.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry Las Vegas\nQ: \"Which color is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c83e040dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30145683_d5c57b740dba11ecb1e81171463288e9_34.jpeg",
            30368398
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Flower, Herbaceous peony \"Prairie moon\" - Flickr - nekonomania (1)\n<image>\nCaption: Plumeria (Frangipani) flowers\nQ: \"What color is at the center of both the Plumeria and the Herbaceous peony?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c57b740dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            30343650,
            "webqa/object_perturbation/30105538_d5c13d840dba11ecb1e81171463288e9_35.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Poland's Pavillion at the 2010 World Expo in Shanghai\n<image>\nCaption: Estonia Pavillion at 2010 Shanghai Expo\nQ: \"Which color is found on both the Estonia and Poland Pavilion at Expo 2010?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, there is conflicting information. <RET>"
            }
        ],
        "type": "conflicting",
        "dataset": "webqa",
        "id": "d5c13d840dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30060344_d5c4b87e0dba11ecb1e81171463288e9_36.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Frangipani flowers\nQ: \"What color is the center part of a Frangipani flower?\""
            },
            {
                "from": "gpt",
                "value": "\"The center part of a Frangipani flower is orange.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c4b87e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30338284_d5bc07560dba11ecb1e81171463288e9_25.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Rethel-FR-08-boulangerie Sattin-01\nQ: \"What color is the facade of bakery Sattin et Fils in Rethel, France?\""
            },
            {
                "from": "gpt",
                "value": "\"The facade of the bakery Sattin et Fils in Rethel, France, is colored yellow.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bc07560dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066773_d5c83e040dba11ecb1e81171463288e9_78.jpeg",
            "webqa/object_perturbation/30148061_d5c83e040dba11ecb1e81171463288e9_79.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry Las Vegas\nQ: \"Which color is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health?\""
            },
            {
                "from": "gpt",
                "value": "\"The color gray is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c83e040dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30145683_d5c57b740dba11ecb1e81171463288e9_64.jpeg",
            "webqa/object_perturbation/30368398_d5c57b740dba11ecb1e81171463288e9_65.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Flower, Herbaceous peony \"Prairie moon\" - Flickr - nekonomania (1)\n<image>\nCaption: Plumeria (Frangipani) flowers\nQ: \"What color is at the center of both the Plumeria and the Herbaceous peony?\""
            },
            {
                "from": "gpt",
                "value": "\"Yellow is at the center of both the Plumeria and the Herbaceous peony.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c57b740dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30177807_d5c273340dba11ecb1e81171463288e9_44.jpeg",
            "webqa/object_perturbation/30145245_d5c273340dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Lamborghini Veneno (11225271396)\n<image>\nCaption: 1954 Maserati A6 GCS\nQ: \"What color is both the primary body paint color off the 1954 Maserati A6 GCS and is also present on the wheels of the Lamborghini Veneno?\""
            },
            {
                "from": "gpt",
                "value": "\"Red is the primary body paint color of the 1954 Maserati A6 GCS and is also present on the wheels of the Lamborghini Veneno.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c273340dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30049604_d5c58baa0dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: \u9577\u58fd\u82b1 Kalanchoe blossfeldiana -\u9999\u6e2f\u5317\u5340\u82b1\u9ce5\u87f2\u9b5a\u5c55 North District Flower Show, Hong Kong- (9207641484)\nQ: \"What color are the petals and pistil of a Kalanchoe blossfeldiana?\""
            },
            {
                "from": "gpt",
                "value": "\"The petals and pistil of a Kalanchoe blossfeldiana are brown and brown.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c58baa0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30169184_d5bfec900dba11ecb1e81171463288e9_72.jpeg",
            "webqa/object_perturbation/30082448_d5bfec900dba11ecb1e81171463288e9_73.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Ulysses Butterfly - melbourne zoo\n<image>\nCaption: Aberrated Silverline butterfly, perhaps Cigaritis vulcanus\nQ: \"What are the colors of an Aberrated Silverline and the Ulysses Butterfly?\""
            },
            {
                "from": "gpt",
                "value": "\"They are both dark and light white.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bfec900dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30148222_d5cb7e840dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Rue royale jms\nQ: \"What color are the stripes found painted down the middle of the Rue Royale?\""
            },
            {
                "from": "gpt",
                "value": "\"The stripes found painted down the middle of the Rue Royale are blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cb7e840dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30311467_d5c94c0e0dba11ecb1e81171463288e9_40.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Beauty of architecture. Shah Faisal Mosque in Islamabad, Pakistan\nQ: \"What colors are the striped curb outside the Shah Faisal Mosque?\""
            },
            {
                "from": "gpt",
                "value": "\"The striped curb is yellow and yellow.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c94c0e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30207148_d5cc0aac0dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Fomes fomentarius 63212\nQ: \"What color scheme does the Fomes fomentarius and tree it is attached to share?\""
            },
            {
                "from": "gpt",
                "value": "\"The color scheme they share is orange, orange, and orange.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc0aac0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30328825_d5c72cc60dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Sabah West Coast Bajau women in traditional dress\nQ: \"What color is the blouse in Sabah West Coast Bajau women's traditional dress\""
            },
            {
                "from": "gpt",
                "value": "\"The blouse in Sabah West Coast Bajau women's traditional dress is purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c72cc60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30148462_d5c2f4e40dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Halloween Saturday Night in Lower French Quarter New Orleans 2016 18\nQ: \"What color is the dress?\""
            },
            {
                "from": "gpt",
                "value": "\"The dress is black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c2f4e40dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30168219_d5c190400dba11ecb1e81171463288e9_92.jpeg",
            "webqa/object_perturbation/30113021_d5c190400dba11ecb1e81171463288e9_93.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Malmo-TurningTorso2005August15\n<image>\nCaption: Bangkok Baiyoke Tower\nQ: \"What shape is at the top of both the Baiyoke Tower and the Turning Torso skyscraper?\""
            },
            {
                "from": "gpt",
                "value": "\"The top of both towers have a cone shape.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c190400dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30006022_d5ca7d9a0dba11ecb1e81171463288e9_30.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Amanita parcivolvata 45933\nQ: \"What color is the cap on a Amanita parcivolvata mushroom?\""
            },
            {
                "from": "gpt",
                "value": "\"The cap on a Amanita parcivolvata mushroom is black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5ca7d9a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30059204_d5c1ef900dba11ecb1e81171463288e9_42.jpeg",
            "webqa/object_perturbation/30109003_d5c1ef900dba11ecb1e81171463288e9_43.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Crowning in Syro-Malabar Nasrani Wedding by Mar Gregory Karotemprel\n<image>\nCaption: Two girls in hutsul clothes Ukraine 2017\nQ: \"Which color can be found in both the robes worn by priest of Syro-Malabar Nasrani and traditional cloth worn by little girls around their waist in ukraine?\""
            },
            {
                "from": "gpt",
                "value": "\"Red can be found in both the robes worn by the priest of Syro-Malabar Nasrani and traditional cloth worn by little girls around their waist in ukraine.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c1ef900dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30214886_d5c6422a0dba11ecb1e81171463288e9_48.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: El Jardin de San Marcos\nQ: \"At  the El Jardin de San Marcos structure, what shape is made by the white metal below the \"El Jardin de San Marcos\" sign?\""
            },
            {
                "from": "gpt",
                "value": "\"The white metal below the \"El Jardin de San Marcos\" sign at the El Jardin de San Marcos structure forms a semi-circle.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c6422a0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30343048_d5c610a20dba11ecb1e81171463288e9_40.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: OlympParkSochi2014\nQ: \"What color roofs were on the buildings at the Sochi Olympic Park?\""
            },
            {
                "from": "gpt",
                "value": "\"The roofs on the buildings at the Sochi Olympic Park were blue and blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c610a20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30220815_d5bbd7040dba11ecb1e81171463288e9_41.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Hotel al codega san marco venezia\nQ: \"What color flowers were displayed outside of the Hotel al codega san marco venezia in June of 2011?\""
            },
            {
                "from": "gpt",
                "value": "\"There were yellow flowers outside the hotel.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bbd7040dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30200367_d5c71f600dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Transfigurazione (Raffaello) September 2015-1a\nQ: \"What color garb is the figure of Jesus wearing in The Transfiguration painting by Raphael?\""
            },
            {
                "from": "gpt",
                "value": "\"The garb worn by Jesus in the Transfiguration Painting by Raphael is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c71f600dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30163499_d5c9aa820dba11ecb1e81171463288e9_34.jpeg",
            "webqa/object_perturbation/30235034_d5c9aa820dba11ecb1e81171463288e9_35.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: The Royal Sala Thai, University of Hawaii at Manoa\n<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\nQ: \"What color is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa?\""
            },
            {
                "from": "gpt",
                "value": "\"Gold is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c9aa820dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30076718_d5c5539c0dba11ecb1e81171463288e9_46.jpeg",
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_47.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "\"Both the Agapornis fischeri and Bay-headed Tanager have the color yellow on their face.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30039613_d5bcf6020dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: African American Museum in Phila\nQ: \"What color is the middle of the letter A filled in by in the sign for the African American Museum in Philadelphia?\""
            },
            {
                "from": "gpt",
                "value": "\"In the sign for the African American Museum in Philadelphia, the middle of the letter A is filled in with blue color.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bcf6020dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30176315_d5c074ee0dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Benvenuti Performing Arts Center\nQ: \"What color is the curb painted in front of the fire hydrant at the Benvenuti Performing Arts Center?\""
            },
            {
                "from": "gpt",
                "value": "\"There is a black curb in front of the fire hydrant at the Benvenuti performing Arts Center.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c074ee0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30305488_d5ca61fc0dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Vincent van gogh, autoritratto, 1887 (chicago), 01\nQ: \"What is the color of the inner shirt worn by Vincent van Gogh in his Self-Portrait done in 1887?\""
            },
            {
                "from": "gpt",
                "value": "\"The inner shirt worn by Vincent Van Gogh was blue in his self-portrait done in 1887.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5ca61fc0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30003902_d5c9a2f80dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Golden Gun - International Spy Museum (14592496766)\nQ: \"What color is the backdrop behind the golden gun displayed at the International Spy Museum?\""
            },
            {
                "from": "gpt",
                "value": "\"The backdrop behind the black gun displayed at the International Spy Museum is black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c9a2f80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30085562_d5c7c7e40dba11ecb1e81171463288e9_44.jpeg",
            "webqa/object_perturbation/30346828_d5c7c7e40dba11ecb1e81171463288e9_45.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2018-06-28 10 16 31 View west along Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, Warren County, New Jersey\n<image>\nCaption: 2018-06-28 09 37 51 View east along Interstate 80 just east of Exit 12 in Hope Township, Warren County, New Jersey\nQ: \"What color are the letterings of the road signs to the right of the Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, and to the right of Interstate 80 just east of Exit 12 in Hope Township?\""
            },
            {
                "from": "gpt",
                "value": "\"The lettering of the signs to the right of the Interstate 80 between Exit 12 and Exit 4 in Blairstown Township, and to the right of Interstate 80 just east of Exit 12 in Hope Township, are both black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c7c7e40dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30152303_d5bed92c0dba11ecb1e81171463288e9_26.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Big 12 Championship - Georges Niang\nQ: \"What color is incorporated in the uniforms of both the Oklahoma Sooners and Iowa State Cyclones?\""
            },
            {
                "from": "gpt",
                "value": "\"Red is incorporated in the uniforms of both the Oklahoma Sooners and Iowa State Cyclones.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bed92c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30191630_d5c7ce600dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Manet - Portrait of Berthe Morisot with a Fan, 1874\nQ: \"What is the color of the hand fan held by the lady in Manet's - Portrait of Berthe Morisot with a Fan?\""
            },
            {
                "from": "gpt",
                "value": "\"The hand fan held by the lady in Manet's \"Portrait of Berthe Morisot with a Fan\" is brown.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c7ce600dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30215187_d5c696d00dba11ecb1e81171463288e9_41.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Magnolia obovata 10\nQ: \"What color are Magnolia stamens?\""
            },
            {
                "from": "gpt",
                "value": "\"The stamens of the Magnolia are purple and purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c696d00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30387719_d5bf54ec0dba11ecb1e81171463288e9_80.jpeg",
            "webqa/object_perturbation/30237804_d5bf54ec0dba11ecb1e81171463288e9_81.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Joe Young 2018\n<image>\nCaption: 141100 - ID basketball Brett Wilson lays 2 - 3b - 2000 Sydney match photo\nQ: \"Which color is found both in Indian pacers jersey and Australian mens basketball team jersey?\""
            },
            {
                "from": "gpt",
                "value": "\"Yellow is found on both the Indian Pacers jersey and Australian men's basketball team jersey.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bf54ec0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30171458_d5bf82c80dba11ecb1e81171463288e9_30.jpeg",
            "webqa/object_perturbation/30136057_d5bf82c80dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Borthwick Castle, Interior 07\n<image>\nCaption: 2016 Severndroog Castle, interior 04\nQ: \"What colors are found on the chairs in the Borthwick Castle?\""
            },
            {
                "from": "gpt",
                "value": "\"Black, yellow, and yellow are found on the chairs in the Borthwick Castle.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bf82c80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30076718_d5c5539c0dba11ecb1e81171463288e9_30.jpeg",
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "\"Both the Agapornis fischeri and Bay-headed Tanager have the color purple on their face.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30173409_d5bef6be0dba11ecb1e81171463288e9_64.jpeg",
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_65.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "\"The color yellow is found on both the Serbia and France Pavilion in 2010 Expo.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30312328_d5c62b960dba11ecb1e81171463288e9_32.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: First Presbyterian Church Schenectady\nQ: \"What color is the bell wheel in the steeple of First Presbyterian Church in Schenectady?\""
            },
            {
                "from": "gpt",
                "value": "\"The bell wheel in the steeple of First Presbyterian Church in Schenectady is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c62b960dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30072784_d5c0fea00dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Fuji TV headquarters and Aqua City Odaiba - 2006-05-03-2009-25-01\nQ: \"What is the shape of the structure on the Fuji TV headquarters?\""
            },
            {
                "from": "gpt",
                "value": "\"The structure is a hexagon.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c0fea00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30368471_d5c130e60dba11ecb1e81171463288e9_26.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 1980 USSR stamp Olympic mascot\nQ: \"What colors of flames are emitted from the torch on the 1980 USSR Olympic mascot stamp?\""
            },
            {
                "from": "gpt",
                "value": "\"On the 1980 USSR Olympic mascot stamp, the color of the flames emitted from the torch are black, black, black, black, and black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c130e60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30100267_d5cc674a0dba11ecb1e81171463288e9_32.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 20130807 dublin157\nQ: \"What color paint is painted on the Temple bar in dublin?\""
            },
            {
                "from": "gpt",
                "value": "\"The Temple bar in Dublin is pink.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc674a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30347423_d5c53bdc0dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Dysphania percota at Kadavoor\nQ: \"What color are the top tips of the wings on a Dysphania percota?\""
            },
            {
                "from": "gpt",
                "value": "\"The top tips of the wings on a Dysphania percota are white.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c53bdc0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30363846_d5c657e20dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Pearl Reference Snare drum\nQ: \"What color is the Pearl Reference Snare drum?\""
            },
            {
                "from": "gpt",
                "value": "\"The Pearl Reference Snare drum is both brown and brown.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c657e20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30059204_d5c1ef900dba11ecb1e81171463288e9_64.jpeg",
            "webqa/object_perturbation/30109003_d5c1ef900dba11ecb1e81171463288e9_65.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Crowning in Syro-Malabar Nasrani Wedding by Mar Gregory Karotemprel\n<image>\nCaption: Two girls in hutsul clothes Ukraine 2017\nQ: \"Which color can be found in both the robes worn by priest of Syro-Malabar Nasrani and traditional cloth worn by little girls around their waist in ukraine?\""
            },
            {
                "from": "gpt",
                "value": "\"Red can be found in both the robes worn by the priest of Syro-Malabar Nasrani and traditional cloth worn by little girls around their waist in ukraine.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c1ef900dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066773_d5c83e040dba11ecb1e81171463288e9_94.jpeg",
            "webqa/object_perturbation/30148061_d5c83e040dba11ecb1e81171463288e9_95.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry Las Vegas\nQ: \"Which color is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health?\""
            },
            {
                "from": "gpt",
                "value": "\"The color pink is found on both MIT Building 32 and the Lou Ruvo Center for Brain Health.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c83e040dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30232510_d5c5d24a0dba11ecb1e81171463288e9_47.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Rudbeckia hirta (black-eyed susan) (Newark, Ohio, USA) 1 (29476036578)\nQ: \"What color appears at the center of a flower from the Rudbeckia hirta plant?\""
            },
            {
                "from": "gpt",
                "value": "\"The center of a Rudbeckia hirta bloom is red.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5d24a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30328825_d5c72cc60dba11ecb1e81171463288e9_42.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Sabah West Coast Bajau women in traditional dress\nQ: \"What color is the blouse in Sabah West Coast Bajau women's traditional dress\""
            },
            {
                "from": "gpt",
                "value": "\"The blouse in Sabah West Coast Bajau women's traditional dress is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c72cc60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30018444_d5c400280dba11ecb1e81171463288e9_46.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Madison Square Garden (4432377106)\nQ: \"What color is the middle section of seating at Madison Square guarden?\""
            },
            {
                "from": "gpt",
                "value": "\"The middle section of seating at Madison Square garden is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c400280dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30087976_d5c309980dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Bethesda Terrace in the time of pandemic\nQ: \"What shaped structures are found a the bottom of the steps of the Bethesda Terrace?\""
            },
            {
                "from": "gpt",
                "value": "\"There are arches at the bottom of the steps of the Bethesda Terrace.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c309980dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30287426_d5ccc06e0dba11ecb1e81171463288e9_40.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Match Stade Olympique Montreal\nQ: \"What shape does the overhead skylight at  Olympic Stadium of Montreal make?\""
            },
            {
                "from": "gpt",
                "value": "\"Montreal's Olympic Stadium has a hexagon overhead skylight.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5ccc06e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30193626_d5c2f55c0dba11ecb1e81171463288e9_32.jpeg",
            "webqa/object_perturbation/30355132_d5c2f55c0dba11ecb1e81171463288e9_33.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arriva bus VXE724 (YJ11 TVE), 11 August 2013\n<image>\nCaption: Sights and sightseers - geograph.org.uk - 1903726\nQ: \"What colors are on both the The Original Tour bus and the Tower bridge in London?\""
            },
            {
                "from": "gpt",
                "value": "\"The Original Tour bus and the Tower Bridge in London both contain the colors blue, blue, blue and blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c2f55c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30003902_d5c9a2f80dba11ecb1e81171463288e9_41.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Golden Gun - International Spy Museum (14592496766)\nQ: \"What color is the backdrop behind the golden gun displayed at the International Spy Museum?\""
            },
            {
                "from": "gpt",
                "value": "\"The backdrop behind the purple gun displayed at the International Spy Museum is purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c9a2f80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30220332_d5c37f4a0dba11ecb1e81171463288e9_30.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Ablyazin, Petrounias, Zanetti Rio 2016b\nQ: \"What color jacket did the men's gymnastics gold medalist wear at the 2016 Summer Olympics?\""
            },
            {
                "from": "gpt",
                "value": "\"The men's gymnastics red medalist wore a red jacket at the 2016 Summer Olympics.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c37f4a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30363896_d5cc77b20dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arthurs seat edinburgh\nQ: \"In what colors does the name City Art Center appear on the front of the City Art Center building in Edinburgh?\""
            },
            {
                "from": "gpt",
                "value": "\"In Edinburgh, the name, \"City Art Center\" appears in both yellow and yellow colors on the front of the City Art Center building.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc77b20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30124204_d5cc38a60dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Pro Football Hall of Fame (23945585187)\nQ: \"What color is Aaron Rodgers' jersey that is on display at the Pro Football Hall of Fame?\""
            },
            {
                "from": "gpt",
                "value": "\"Aaron Rodgers' jersey that is on display at the Pro Football Hall of Fame is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc38a60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30006022_d5ca7d9a0dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Amanita parcivolvata 45933\nQ: \"What color is the cap on a Amanita parcivolvata mushroom?\""
            },
            {
                "from": "gpt",
                "value": "\"The cap on a Amanita parcivolvata mushroom is brown.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5ca7d9a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30337052_d5c497180dba11ecb1e81171463288e9_28.jpeg",
            "webqa/object_perturbation/30088225_d5c497180dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: EMG office building, 2018 Sashalom\n<image>\nCaption: Knoxville Building Office LBMC\nQ: \"Which colors are found on both the Knoxville Building Office LBMC and the EMG office building?\""
            },
            {
                "from": "gpt",
                "value": "\"Both buildings share the colors yellow and yellow.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c497180dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30061122_d5c5c1100dba11ecb1e81171463288e9_36.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Carpodacus cassinii1\nQ: \"What color is the crown of the Cassin's Finch?\""
            },
            {
                "from": "gpt",
                "value": "\"The Cassin's Finch has a yellow crown.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5c1100dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30060344_d5c4b87e0dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Frangipani flowers\nQ: \"What color is the center part of a Frangipani flower?\""
            },
            {
                "from": "gpt",
                "value": "\"The center part of a Frangipani flower is pink.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c4b87e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30142352_d5c0af5e0dba11ecb1e81171463288e9_54.jpeg",
            "webqa/object_perturbation/30305558_d5c0af5e0dba11ecb1e81171463288e9_55.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: KFC, North End Road, Fulham, London 01\n<image>\nCaption: Chicken Cottage, North End Road, Fulham, London 01\nQ: \"What color is the background of the KFC restaurant and Chicken Cottage restaurant sign?\""
            },
            {
                "from": "gpt",
                "value": "\"The background of the KFC restaurant and Chicken Cottage restaurant sign is yellow.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c0af5e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30158844_d5c7e67a0dba11ecb1e81171463288e9_42.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Campanile of St. Mark's Basilica - remote view\nQ: \"What color is the roof of the Campanile of St. Mark's Basilica?\""
            },
            {
                "from": "gpt",
                "value": "\"The roof of the Campanile of St. Mark's Basilica is red.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c7e67a0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30254901_d5c73cb60dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Vista do Hospital Ferreira Machado, Campos dos Goytacazes RJ\nQ: \"What colors are the Hospital Ferreira Machado building as depicted in its sign?\""
            },
            {
                "from": "gpt",
                "value": "\"The Hospital Ferreira Machado building has pink and pink depicted in its sign.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c73cb60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30173409_d5bef6be0dba11ecb1e81171463288e9_38.jpeg",
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "\"The color purple is found on both the Serbia and France Pavilion in 2010 Expo.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30057678_d5c9ecc20dba11ecb1e81171463288e9_30.jpeg",
            "webqa/object_perturbation/30141396_d5c9ecc20dba11ecb1e81171463288e9_31.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Meidan Emam, Esfahan-130683\n<image>\nCaption: Entrace to Imam (Shah) Mosque, Esfahan, Iran (14471624621)\nQ: \"What color is featured in Interior of the Sheikh Lotfollah Mosque, Meidan Emam, Esfahan that isn't in the Entrance to Imam (Shah) Mosque, Esfahan, Iran?\""
            },
            {
                "from": "gpt",
                "value": "\"The Sheikh Lotfollah Mosque includes the color blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c9ecc20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30228575_d5bd6b460dba11ecb1e81171463288e9_46.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Classroom in Niue\nQ: \"What color shirt can be worn as part of the uniform in a classroom in Niue?\""
            },
            {
                "from": "gpt",
                "value": "\"White or pink shirts are part of the uniform.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bd6b460dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30252255_d5c701a60dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Castro district\nQ: \"What color is the facade of the building that house has Harvey's restaurant in Castro?\""
            },
            {
                "from": "gpt",
                "value": "\"The facade of the building that houses Harvey's restaurant in Castro is purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c701a60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30345877_d5c661560dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Amarynthismenerastenagramma\nQ: \"What color is the stripe on the wings of the Amarynthis menera stenagramma?\""
            },
            {
                "from": "gpt",
                "value": "\"The stripe on the wings of the Amarynthis Menera Stenagramma is purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c661560dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30027761_d5c76d760dba11ecb1e81171463288e9_36.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Eli Bremer in 2008 Summer Olympics modern pentathlon show jumping event 1\nQ: \"What color horse did Eli Bremer ride in the 2008 Summer Olympics?\""
            },
            {
                "from": "gpt",
                "value": "\"Eli Bremer rode a brown horse in the 2008 Summer Olympics.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c76d760dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30252255_d5c701a60dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Castro district\nQ: \"What color is the facade of the building that house has Harvey's restaurant in Castro?\""
            },
            {
                "from": "gpt",
                "value": "\"The facade of the building that houses Harvey's restaurant in Castro is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c701a60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30365032_d5c334860dba11ecb1e81171463288e9_90.jpeg",
            "webqa/object_perturbation/30367480_d5c334860dba11ecb1e81171463288e9_91.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Eiffel Tower Las Vegas 30MAR19\n<image>\nCaption: THE PARIS (VEGAS)\nQ: \"The Eifel Tower at Paris Las Vegas is lighted with what color lights at night?\""
            },
            {
                "from": "gpt",
                "value": "\"The Eiffel Tower at Paris Las Vegas is lighted with yellow lights at night.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c334860dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30338284_d5bc07560dba11ecb1e81171463288e9_39.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Rethel-FR-08-boulangerie Sattin-01\nQ: \"What color is the facade of bakery Sattin et Fils in Rethel, France?\""
            },
            {
                "from": "gpt",
                "value": "\"The facade of the bakery Sattin et Fils in Rethel, France, is colored blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bc07560dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30173409_d5bef6be0dba11ecb1e81171463288e9_80.jpeg",
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_81.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "\"The color pink is found on both the Serbia and France Pavilion in 2010 Expo.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066773_d5cd33640dba11ecb1e81171463288e9_86.jpeg",
            "webqa/object_perturbation/30324476_d5cd33640dba11ecb1e81171463288e9_87.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Stata Center (MIT Building 32) 05\n<image>\nCaption: Gehry buildings Duesseldorf Neuer Zollhof 2 Unterbilk Duesseldorf Germany 01\nQ: \"Which color is found on both MIT Building 32 and Neuer Zollhof no. 2?\""
            },
            {
                "from": "gpt",
                "value": "\"The colour blue is found on both MIT Building 32 and Neuer Zollhof no. 2.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cd33640dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30081258_d5cbec200dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: KAM Fort Worth\nQ: \"What shape is the roof of the Kimbell Art Museum in Texas?\""
            },
            {
                "from": "gpt",
                "value": "\"The roof is curved.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cbec200dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30152303_d5bed92c0dba11ecb1e81171463288e9_28.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Big 12 Championship - Georges Niang\nQ: \"What color is incorporated in the uniforms of both the Oklahoma Sooners and Iowa State Cyclones?\""
            },
            {
                "from": "gpt",
                "value": "\"Red is incorporated in the uniforms of both the Oklahoma Sooners and Iowa State Cyclones.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bed92c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30254901_d5c73cb60dba11ecb1e81171463288e9_46.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Vista do Hospital Ferreira Machado, Campos dos Goytacazes RJ\nQ: \"What colors are the Hospital Ferreira Machado building as depicted in its sign?\""
            },
            {
                "from": "gpt",
                "value": "\"The Hospital Ferreira Machado building has black and black depicted in its sign.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c73cb60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30173409_d5bef6be0dba11ecb1e81171463288e9_52.jpeg",
            "webqa/object_perturbation/30206105_d5bef6be0dba11ecb1e81171463288e9_53.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Serbia Pavilion of Shanghai Expo 2010\n<image>\nCaption: France Pavilion of Shanghai Expo\nQ: \"Which color is found on both the Serbia and France Pavilion in 2010 Expo?\""
            },
            {
                "from": "gpt",
                "value": "\"The color purple is found on both the Serbia and France Pavilion in 2010 Expo.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bef6be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30009487_d5bd99860dba11ecb1e81171463288e9_88.jpeg",
            "webqa/object_perturbation/30143140_d5bd99860dba11ecb1e81171463288e9_89.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Torch 2012 at Jodrell Bank 1\n<image>\nCaption: 2008 Olympic Torch Relay, London AB3\nQ: \"What color appeared on the uniform for the 2012 Olympic Torch carriers that didn't appear on the uniforms for the 2008 carriers?\""
            },
            {
                "from": "gpt",
                "value": "\"The color white appeared on the uniform for the 2012 Olympic Torch carriers and didn't appear on the uniforms for the 2008 carriers.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bd99860dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30163499_d5c9aa820dba11ecb1e81171463288e9_72.jpeg",
            "webqa/object_perturbation/30235034_d5c9aa820dba11ecb1e81171463288e9_73.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: The Royal Sala Thai, University of Hawaii at Manoa\n<image>\nCaption: A Thai pavilion in National Museum (Bangkok)\nQ: \"What color is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa?\""
            },
            {
                "from": "gpt",
                "value": "\"Gold is featured prominently on both the Thai pavilion in National Museum of Bangkok and The Royal Sala Thai on the campus of the University of Hawaii at Manoa.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c9aa820dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30074316_d5c5a5220dba11ecb1e81171463288e9_48.jpeg",
            "webqa/object_perturbation/30044834_d5c5a5220dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Berlin Cathedral 01\n<image>\nCaption: Schloss Charlottenburg Berlin 2007\nQ: \"What colors do the roof domes Schloss Charlottenburg in Berlin and the Berlin Cathedral share?\""
            },
            {
                "from": "gpt",
                "value": "\"The color the roof domes Schloss Charlottenburg in Berlin and the Berlin Cathedral share is light purple.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5a5220dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30120191_d5c7a2280dba11ecb1e81171463288e9_49.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Barcelona - El Pez, de Frank Gehry 2\nQ: \"What color are the supports for the giant fish sculpture at Olympic Park in Barcelona?\""
            },
            {
                "from": "gpt",
                "value": "\"The supports for the enormous fish sculpture at Barcelona's Olympic Park are orange.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c7a2280dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30322210_d5c895980dba11ecb1e81171463288e9_47.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Flussregenpfeifer Little ringed plover 2\nQ: \"What color is the Little Ringed Plover's eye ring?\""
            },
            {
                "from": "gpt",
                "value": "\"The Little Ringed Plover's eye ring is black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c895980dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30363896_d5cc77b20dba11ecb1e81171463288e9_38.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Arthurs seat edinburgh\nQ: \"In what colors does the name City Art Center appear on the front of the City Art Center building in Edinburgh?\""
            },
            {
                "from": "gpt",
                "value": "\"In Edinburgh, the name, \"City Art Center\" appears in both red and red colors on the front of the City Art Center building.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc77b20dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30076718_d5c5539c0dba11ecb1e81171463288e9_28.jpeg",
            "webqa/object_perturbation/30381798_d5c5539c0dba11ecb1e81171463288e9_29.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Agapornis fischeri -Ueno Zoo, Japan -three-8a-4c\n<image>\nCaption: Bay-headed Tanager - San Luis - Costa Rica MG 1171 (26075030873)\nQ: \"What color do the Agapornis fischeri and Bay-headed Tanager both have on their face?\""
            },
            {
                "from": "gpt",
                "value": "\"Both the Agapornis fischeri and Bay-headed Tanager have the color orange on their face.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c5539c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30087976_d5c309980dba11ecb1e81171463288e9_48.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Bethesda Terrace in the time of pandemic\nQ: \"What shaped structures are found a the bottom of the steps of the Bethesda Terrace?\""
            },
            {
                "from": "gpt",
                "value": "\"There are arches at the bottom of the steps of the Bethesda Terrace.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c309980dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30368471_d5c130e60dba11ecb1e81171463288e9_38.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 1980 USSR stamp Olympic mascot\nQ: \"What colors of flames are emitted from the torch on the 1980 USSR Olympic mascot stamp?\""
            },
            {
                "from": "gpt",
                "value": "\"On the 1980 USSR Olympic mascot stamp, the color of the flames emitted from the torch are pink, pink, pink, pink, and pink.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c130e60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066686_d5c6d82a0dba11ecb1e81171463288e9_26.jpeg",
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_27.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "\"Brown is found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30066686_d5c6d82a0dba11ecb1e81171463288e9_62.jpeg",
            "webqa/object_perturbation/30017626_d5c6d82a0dba11ecb1e81171463288e9_63.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UA Dance Building\n<image>\nCaption: 09 25 DOM SZ 2\nQ: \"Which colors are found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland?\""
            },
            {
                "from": "gpt",
                "value": "\"Brown is found on both the Dance Building at the University of Arizona and the 'upside-down house' in an open-air museum in Szybmark, northern Poland.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c6d82a0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30327560_d5c533d00dba11ecb1e81171463288e9_70.jpeg",
            "webqa/object_perturbation/30309162_d5c533d00dba11ecb1e81171463288e9_71.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Beijing Qianmen 2008\n<image>\nCaption: Beijing Daxing International Airport 12\nQ: \"What color on the ceiling of Beijing Daxing International Airport is the same as the color used to illuminate signs above Qianmen, Beijing ?\""
            },
            {
                "from": "gpt",
                "value": "\"The color they have in common is red.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c533d00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30191630_d5c7ce600dba11ecb1e81171463288e9_33.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Manet - Portrait of Berthe Morisot with a Fan, 1874\nQ: \"What is the color of the hand fan held by the lady in Manet's - Portrait of Berthe Morisot with a Fan?\""
            },
            {
                "from": "gpt",
                "value": "\"The hand fan held by the lady in Manet's \"Portrait of Berthe Morisot with a Fan\" is blue.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c7ce600dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30318730_d5c3b7620dba11ecb1e81171463288e9_52.jpeg",
            "webqa/object_perturbation/30287563_d5c3b7620dba11ecb1e81171463288e9_53.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Closed playground in New York City on April 1st, 2020\n<image>\nCaption: Central Park tent hospital (1) jeh\nQ: \"What color are the tents while the sign indicates that the playground is what?\""
            },
            {
                "from": "gpt",
                "value": "\"The tents are red while the sign indicates that the playground is closed.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c3b7620dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30015835_d5c27e2e0dba11ecb1e81171463288e9_40.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Rodeo Drive LA\nQ: \"What color does the city paint the curb to prevent people from parking their vehicles on certain parts of Rodeo Drive?\""
            },
            {
                "from": "gpt",
                "value": "\"The city paints the curb gray to prevent parking on certain parts of Rodeo Drive.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c27e2e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30320934_d5bfd7640dba11ecb1e81171463288e9_38.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Taiwan Lantern Festival, Yunlin (Taiwan)\nQ: \"What is the color of most lanterns at the entry for 2017 Taiwan Lantern Festival, Yunlin County, Taiwan?\""
            },
            {
                "from": "gpt",
                "value": "\"Most of the lanterns at the entry for 2017 Taiwan Lantern Festival, Yunlin County, Taiwan were white.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bfd7640dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30320934_d5bfd7640dba11ecb1e81171463288e9_48.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2017 Taiwan Lantern Festival, Yunlin (Taiwan)\nQ: \"What is the color of most lanterns at the entry for 2017 Taiwan Lantern Festival, Yunlin County, Taiwan?\""
            },
            {
                "from": "gpt",
                "value": "\"Most of the lanterns at the entry for 2017 Taiwan Lantern Festival, Yunlin County, Taiwan were gold.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5bfd7640dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30100267_d5cc674a0dba11ecb1e81171463288e9_25.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 20130807 dublin157\nQ: \"What color paint is painted on the Temple bar in dublin?\""
            },
            {
                "from": "gpt",
                "value": "\"The Temple bar in Dublin is white.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc674a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30242577_d5c45bc20dba11ecb1e81171463288e9_37.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: BroadwayPlazaRochMN\nQ: \"What color is the tallest building on Broadway Plaza?\""
            },
            {
                "from": "gpt",
                "value": "\"The tallest building on Broadway Plaza is pink.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c45bc20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30310069_d5ca59aa0dba11ecb1e81171463288e9_33.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Park, London, 16 April 2012\nQ: \"During the final construction of the Olympic Park stadium in London on April 16th, 2012, what shape was the green field inside of the stadium?\""
            },
            {
                "from": "gpt",
                "value": "\"During the final construction of the Olympic Park stadium in London on April 16th, 2012, the green field inside of the stadium was hexagon.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5ca59aa0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30018444_d5c400280dba11ecb1e81171463288e9_47.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Madison Square Garden (4432377106)\nQ: \"What color is the middle section of seating at Madison Square guarden?\""
            },
            {
                "from": "gpt",
                "value": "\"The middle section of seating at Madison Square garden is black.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c400280dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30262055_d5c3d0440dba11ecb1e81171463288e9_42.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Carcassonne, Aude, Mus\u00e9e des Beaux-Arts (2)\nQ: \"What color are the second story window-like structures at The Museum of Fine Arts of Carcassonne?\""
            },
            {
                "from": "gpt",
                "value": "\"The second story window-like structures at The Museum of Fine Arts of Carcassonne are gold.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c3d0440dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30016611_d5c4f8f20dba11ecb1e81171463288e9_35.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Edgar degas, piccola ballerina, 14 anni, 1879-81, 01\nQ: \"What shape is the base of the ballerina sculpture in the Art Institute of Chicago?\""
            },
            {
                "from": "gpt",
                "value": "\"The base of the ballerina sculpture in the Art Institute of Chicago has a cross shape.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5c4f8f20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30320497_d5be1c760dba11ecb1e81171463288e9_42.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: China merchants bank tower\nQ: \"What color is the logo on China Merchants Bank Tower?\""
            },
            {
                "from": "gpt",
                "value": "\"The logo on China Merchants Bank Tower is white and white .\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5be1c760dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30284416_d5cc857c0dba11ecb1e81171463288e9_25.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: PL-PK Mielec, rze\u017aba Gryf 2016-05-06--11-35-16-004\nQ: \"What color is the Griffin statue on Market Square in Mielec?\""
            },
            {
                "from": "gpt",
                "value": "\"The color of the Griffin statue on Market Square in Mielec is red.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc857c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30286934_d5cc39d20dba11ecb1e81171463288e9_44.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: St Albans Church Copenhagen organ\nQ: \"The approach to the St Albans Church Copenhagen organ is blocked off by a rope of what color?\""
            },
            {
                "from": "gpt",
                "value": "\"The approach to the St. Albans Church Copenhagen's organ is blocked off by yellow rope.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc39d20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "webqa/object_perturbation/30124204_d5cc38a60dba11ecb1e81171463288e9_30.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Pro Football Hall of Fame (23945585187)\nQ: \"What color is Aaron Rodgers' jersey that is on display at the Pro Football Hall of Fame?\""
            },
            {
                "from": "gpt",
                "value": "\"Aaron Rodgers' jersey that is on display at the Pro Football Hall of Fame is orange.\""
            }
        ],
        "type": "perturbed",
        "dataset": "webqa",
        "id": "d5cc38a60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30193086_d5c048fc0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30235845_d5c048fc0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: British Museum entrance\n<image>\nCaption: British museum facade (1)\nQ: \"Does the British Museum always feature the same banners displayed by its entrance?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c048fc0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30304142_d5bf819c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Dubai Mall gallery, 6 December 2008\nQ: \"Is the Dubai Mall less than 3 stories tall?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bf819c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30161294_d5c2a8d60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Boston Public Garden - Boston, MA - DSC01502\nQ: \"Is the man on the horse statue at the Boston Public Garden wearing a hat and an overcoat?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2a8d60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30024785_d5c413b00dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30115593_d5c413b00dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Gathering in Woodruff\n<image>\nCaption: CNN Center, Atlanta, Georgia\nQ: \"Do more people gather in Woodruff Park than in front of the CNN logo at the CNN center, both located in Atlanta?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c413b00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30080818_d5c202280dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Moore College of Art & Design\nQ: \"Is the Moore College of Art & Design in Philadelphia the tallest building in it's neighborhood?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c202280dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30365649_d5c453ac0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Soho palace theatre 1\nQ: \"Is there a crosswalk that leads to the entrance of the Soho Palace Theatre in London?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c453ac0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30267705_d5c4f8d40dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mycena renati 46728\nQ: \"Do all Mycena renati grow to the same height?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4f8d40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30388609_d5bf36240dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Cross-Baie-Cavali\u00e8re-Annonciade\nQ: \"Are there only  two people in Henri-Edmond Cross's painting, The Beach at Saint-Clair?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bf36240dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30373226_d5c0f7a20dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2018 Commonwealth Games opening ceremony.jpeg\nQ: \"At the 2018 Commonwealth Games opening ceremony, is the floating whale the highest object in the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c0f7a20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30045262_d5c043660dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30137785_d5c043660dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: UrisLibrary24\n<image>\nCaption: Cornell Law School Tower 2019-10-04 22-20\nQ: \"Do both the Cornell Law School Tower and McGraw Tower have a clock on them?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c043660dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30067215_d5c032d60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30093789_d5c032d60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: DothanCivicCenter2\n<image>\nCaption: DothanCivicCenter1\nQ: \"Are the lampposts around the Dothan Civic Center all at the same level in comparison to the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c032d60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30067698_d5c32b940dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Alexander Hamilton Custom House Collector's Room fireplace (40531s)\nQ: \"Are faces sculpted into the fireplace in the Collector's Office of the Alexander Hamilton U. S. Custom House?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c32b940dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30054090_d5c2d9be0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30329629_d5c2d9be0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Atlantic Terminal td (2018-10-03) 09 - Barclays Center\n<image>\nCaption: Afrocrowd 2016-05-22 group c cut jeh\nQ: \"Does the view eastwards in the computer room of BPL have more scenery than the view looking northeast at a former tollbooth of the Plank Road?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2d9be0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30185982_d5bf95600dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30366412_d5bf95600dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Lion-tailed Macaque in Bristol Zoo\n<image>\nCaption: Cotton Top Tamarin by Trisha\nQ: \"Does the long hair on the head of the Lion-tailed Macaque and the Cotton Top Tamarin both emerge from their face?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bf95600dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30137120_d5c2c4f60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30006154_d5c2c4f60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Atlantic Terminal td (2018-10-03) 36 - Williamsburgh Savings Bank Tower\n<image>\nCaption: Coney Is Beach td (2018-09-03) 66 - Childs Restaurant (Ford Amphitheater)\nQ: \"Are the Williamsburgh Savings Bank Tower and the former Childs Restaurant in Brooklyn both taller than 10 stories?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2c4f60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30273834_d5c010300dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Chinese-style minaret of the Great Mosque\nQ: \"The Great Mosque has benches in front of it?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c010300dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30382128_d5c158000dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30241701_d5c158000dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2006 AEGold Proof Rev.png\n<image>\nCaption: 2006 AEGold Proof Obv.png\nQ: \"Is the same animal found on both the front and back of the 2006 AE Gold Proof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c158000dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30055427_d5c2e8e60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: PittCampus\nQ: \"Is the Cathedral of learning visible if you're in Schenley Plaza?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2e8e60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30263391_d5c5e5460dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Bin Dawood Nabawi Mosque 3\nQ: \"Is the facade of the Bin Dawood Nabawi Mosque all one color?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5e5460dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30357802_d5c506940dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30159649_d5c506940dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Waterloo BridgeConstable\n<image>\nCaption: Italian Landscape by Jean-Victor Bertin, 1812, oil on canvas - National Museum of Western Art, Tokyo - DSC08571\nQ: \"Is the bridge in the \"Italian Landscape\" painting by Jean-Victor Bertin larger than the bridge in the background of the painting \"The Opening of Waterloo Bridge\"?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c506940dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30213287_d5c5730e0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30386245_d5c5730e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mycena epipterygia - Lindsey 5a\n<image>\nCaption: Zitzen-Riesenschirmling Macrolepiota mastoidea\nQ: \"Do both Mycena epipterygia and Macrolepiota mastoidea both have pointed caps?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5730e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30207054_d5beb2ee0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Street art dragon, City Road, Cardiff, Wales (26772648516)\nQ: \"Is the Street art dragon in Cardiff, Wales larger than one story tall?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5beb2ee0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30050033_d5c2d3740dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30380080_d5c2d3740dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: MTA Deploys PPE Vending Machines Across Subway System (50062065252)\n<image>\nCaption: New York City Transit Crews Complete Deep-Cleaning of City Hall Station (50144761397)\nQ: \"Do both Brooklyn Bridge City Hall station billboard and vending machine in subway system have signage on PPE?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2d3740dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30340775_d5c464000dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30220106_d5c464000dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: United States Capitol, Washington\n<image>\nCaption: Exterior of the United States Capitol - 3\nQ: \"Do the black planters around the rounded tier of the United States Capitol, Washington always contain plants?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c464000dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30346474_d5c5ec440dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Dendrocopos major-2c\nQ: \"Can a Great Spotted Woodpecker climb a tree?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5ec440dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30061631_d5c4e02e0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30166064_d5c4e02e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: St Bartholomew the Great, West Smithfield, London EC1 - geograph.org.uk - 1142484\n<image>\nCaption: St Bartholomew the great churchyard\nQ: \"Are the clock hands on St. Bartholomew the Great stuck in one position?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4e02e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30370383_d5c340660dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Atlanta Fulton Public Main Library, Atlanta, GA (40508251003)\nQ: \"Is the entire exterior wall of Fulton Public Library in Atlanta flat?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c340660dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30089695_d5bf10d60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30105628_d5bf10d60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Graceland Memphis Tennessee\n<image>\nCaption: Graceland Randers 01\nQ: \"Have there always been white benches at the front entrance of Graceland?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bf10d60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30232299_d5bd5dc20dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 102 Casa Josep Fitella, c. Consell de Cent 189 - c. Comte d'Urgell 95 (Barcelona)\nQ: \"Is parking allowed in front of Casa Josep Fitella?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bd5dc20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30310018_d5c397140dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30182926_d5c397140dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Southgate Hall, East Campus, Duke University, Durham, NC (48961171762)\n<image>\nCaption: Southgate Hall, East Campus, Duke University, Durham, NC (48961169482)\nQ: \"Does Southgate Hall at Duke University have a flat roof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c397140dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30207704_d5c32f400dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Halloween Parade 2016 (30281434421)\nQ: \"Does Vancouver permit holiday parades to use one way streets?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c32f400dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30165688_d5c4a6cc0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30259399_d5c4a6cc0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Olympic Village, London, 16 April 2012\n<image>\nCaption: Rio2016 julho VilaAtletas Barra 002 2659 -c-2016 GabrielHeusi HeusiAction\nQ: \"Is there a tennis court near both the Olympic villa in Rio and the Olympic villa in London?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4a6cc0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30144370_d5bbf1da0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30304233_d5bbf1da0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Lyric Theater, Blacksburg\n<image>\nCaption: Lyric Theater, Waycross Historic District, GA, US\nQ: \"Are the colors of the word lyric different in the Lyric Theater, Blacksburg and Lyric Theater, Georgia signs?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bbf1da0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30044209_d5beffb00dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: ArgentineAntarcticEsperanza\nQ: \"Is there a satellite dish close to the water at Esperanza?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5beffb00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30118088_d5c4288c0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30183073_d5c4288c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Issac M. Wise Plum Street Temple, Cincinnati, OH (33477363088)\n<image>\nCaption: Issac M. Wise Plum Street Temple, Cincinnati, OH (33477369438)\nQ: \"Are the windows on all sides of Plum Street Temple in Cincinnati the same shape?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4288c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30144884_d5c4cbde0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30336494_d5c4cbde0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: LebronFT (cropped)\n<image>\nCaption: Lebron wizards 2017 (cropped)\nQ: \"Did LeBron James always wear the same arm accessories during his time with the Cleveland Cavaliers?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4cbde0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30248415_d5c0e99c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Vakhtang Gorgasali Statue - Tbilisi - 01\nQ: \"Is the horse standing on an inclined base on the Vakhtang Gorgasali Statue?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c0e99c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30352370_d5bff7c60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30250227_d5bff7c60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: COTTON-TOP TAMARIN (7777055928)\n<image>\nCaption: Red-shanked Douc at the Philadelphia Zoo\nQ: \"Do the Red-shanked Douc and the Cotton-top Tamarin have patches of black fur and white fur in the same locations on their heads?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bff7c60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30126059_d5c2b20e0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30261781_d5c2b20e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Wingspread Exterior 23\n<image>\nCaption: Wingspread Interior 20\nQ: \"At Wingspread, is the window trim color on the exterior of the building the same as the window trim color on the interior of the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2b20e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30324063_d5c2f9f80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Laurier Quebec\nQ: \"Are there flowering plants outside Laurier in Quebec?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2f9f80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30067065_d5c2f2c80dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30309370_d5c2f2c80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Hot dog stand in Yankee Stadium 2017\n<image>\nCaption: WYES TV Station New Orleans - Open House Day Sept 2017 09\nQ: \"Do Lucky Dogs hot dog cart and Yankee Stadium hot dog carts both use carts shaped like hot dogs?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2f2c80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30274274_d5c08d940dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30066659_d5c08d940dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Henriette Geertruida Knip - Flowers in a Vase, 1830\n<image>\nCaption: Van Huysum, Michiel - A Delft Vase with Flowers - Google Art Project\nQ: \"Do both Michiel Van Huysum's A Delft Vase with Flowers and Henriette Geertruida Knip's Flowers in a Vase depict a snail?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c08d940dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30090524_d5c2a7500dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30225400_d5c2a7500dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Big bus tours - London, Ankai bus\n<image>\nCaption: Arriva Original Tour VLY604\nQ: \"Do Big Bus Tours and The Original Tour both operate open-air double decker buses?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2a7500dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30307282_d5bdc5e60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30071357_d5bdc5e60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Acanthurus leucostrenon - 2 (E)\n<image>\nCaption: Chaetodon ulietensis Pacific Double-saddle Butterflyfish Beqa by Nick Hobgood\nQ: \"Is the acanthurus leucostrenon's snout as long as the chaetodon ulietensis's snout?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bdc5e60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30225870_d5c538580dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: A Baroque library, Prague - 7551\nQ: \"Do baroque libraries in Prague use bookshelves big enough to stack books two rows deep on one shelf?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c538580dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30340429_d5c29aa80dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30194114_d5c29aa80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Fourth of July Fireworks at Washington DC - 1\n<image>\nCaption: Seattle Great Wheel, Seattle, Washington, Estados Unidos, 2017-09-02, DD 16\nQ: \"Were both Seattle Great Wheel and the fourth of July fireworks at Washington near a water body?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c29aa80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30079629_d5bbc7c80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2020-05-08 15 17 05 Minnetonka Rhododendron flower along Tranquility Court in the Franklin Farm section of Oak Hill, Fairfax County, Virginia\nQ: \"Does a Minnetonka Rhododendron flower have petals in a cup shape?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bbc7c80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30243755_d5c29d8c0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30130401_d5c29d8c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mount Rushmore Fireworks Celebration (50087190127)\n<image>\nCaption: Mount Rushmore Fireworks Celebration (50083499562)\nQ: \"During the 2020 Mount Rushmore Fireworks celebration, were fireworks being blown all day long?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c29d8c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30177903_d5c123b20dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30342971_d5c123b20dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Sculpture Momo Ulrike Enders Michael-Ende-Platz Hanover Germany\n<image>\nCaption: Falstaff statue, Stratford-upon-Avon - DSC08964\nQ: \"Is the person seated in both the Falstaff statue and the Sculpture Momo?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c123b20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30258233_d5c43f980dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Sochi adler aerial view 2018 14\nQ: \"Is the Olympic Torch at the center of Sochi Olympic Park completely encircled by flags?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c43f980dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30041406_d5c46bda0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Smithsonian American Art Museum 02265\nQ: \"Are the lights in the center of the Smithsonian American Art Museum imbedded in the ceiling?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c46bda0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30002725_d5c2e5440dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30254807_d5c2e5440dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: SkyView ATL\n<image>\nCaption: Georgia National Guard - 49957337622\nQ: \"Does Centennial Park contain a Ferris wheel that is illuminated at night but not during daylight hours?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2e5440dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30090218_d5c1669c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Violet-bellied Hummingbird - Ecuador S4E8390\nQ: \"Is the Violet-Bellied Hummingbird monochromatic?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c1669c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30093399_d5c5903c0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30304142_d5c5903c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mercato Shopping Mall - Dubai - \u0645\u064a\u0631\u0643\u0627\u062a\u0648 \u0644\u0644\u062a\u0633\u0648\u0642 - panoramio\n<image>\nCaption: Dubai Mall gallery, 6 December 2008\nQ: \"Do both the Dubai Mall gallery and the Mercato Shopping Mall feature indoor curved roofing?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5903c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30342782_d5c3ce320dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: ChristmasVillage PHL Atmosphere Credit DaveLakatos\nQ: \"Could people visiting the Christmas Village in Philadelphia in LOVE Park bring their pets with them?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3ce320dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30114495_d5c41b940dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: NY Life Park Av jeh\nQ: \"Are there any trees near the New York Life Building which are taller than the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c41b940dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30152853_d5c5405a0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: White trumpet flower Anza-Borrego\nQ: \"Are the petals of the White trumpet flower of the Desert Willow symmetrical?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5405a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30072353_d5c343f40dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Susie Morrison - White House gingerbread house 2010\nQ: \"Does the White House China room contain visible dishes?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c343f40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30344553_d5c3a5420dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30157593_d5c3a5420dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mount Rushmore Fireworks Celebration (50087175522)\n<image>\nCaption: Mount Rushmore Fireworks Celebration (50087212612)\nQ: \"Did the Trumps visit multiple destinations during the 2020 July 4th fireworks at Mt. Rushmore?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3a5420dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30053424_d5c4067c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Wwp50roof\nQ: \"Does One Worldwide Plaza have level sides from top to bottom?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4067c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30310304_d5c500f40dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30331107_d5c500f40dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2015 01 Koh Lanta 30 littlr teeth (16423924129)\n<image>\nCaption: Abe's Anglefish (Centropyge abei), Waikiki Aquarium\nQ: \"Do the Koh Lanta and Abe's Anglefish both have white tail fins?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c500f40dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30140050_d5bfd2fa0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30206009_d5bfd2fa0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Apostle Bartholomew on St.Isaac cathedral (SPb)\n<image>\nCaption: Bartholomaeus San Giovanni in Laterano 2006-09-07\nQ: \"Are the statues of Apostle Bartholomew at St.Isaac cathedral and the one at San Giovanni in Laterano both holding something in each of their hands?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bfd2fa0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30293364_d5c5c8180dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30201014_d5c5c8180dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Petit Champlain at night, Quebec city\n<image>\nCaption: Champlain Quebec city\nQ: \"Has the signage on Rue du Petit-Champlain always been the same?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c5c8180dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30389333_d5c16d860dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30032530_d5c16d860dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Chair of Saint Peter\n<image>\nCaption: Saint Peter's Basilica\nQ: \"Can one always see sunbeams coming down at the front interior of St. Peter's Cathedral?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c16d860dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30163766_d5c0a4aa0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: FAU Davie Campus\nQ: \"Do trees block the etching in the entrance of FAU Davie Campus?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c0a4aa0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30149471_d5bd98a00dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30223015_d5bd98a00dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: AT 13763 Roof figures at the Kunsthistorisches Museum, Vienna-71-Bearbeitet\n<image>\nCaption: AT 13763 Roof figures at the Kunsthistorisches Museum, Vienna-11\nQ: \"Are all of the statues on the roof of the Kunsthistorisches Museum in Vienna depicted holding something in their hand?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bd98a00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30178627_d5c34d5e0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30038311_d5c34d5e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Diagon Alley Entrance (29464778148)\n<image>\nCaption: Flimflam's Lanterns (42428011985)\nQ: \"Are there older looking buildings at Universal Studios?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c34d5e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30008538_d5c41ea00dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30332755_d5c41ea00dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: SkyView Atlanta close 12313\n<image>\nCaption: Winecoff-Hotel-Atlanta-01\nQ: \"Are both a Ferris wheel and the Ellis Hotel found near a traffic light in Atlanta?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c41ea00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30360027_d5c51cd80dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30061230_d5c51cd80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Runway ninja model with a gun (6210195288)\n<image>\nCaption: Movie star quality sfpd, castro street fair (2011) (6210183122)\nQ: \"Are the midway caps worn by both men and women in the San Francisco police department the same color?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c51cd80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30162174_d5c4a0d20dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Coney Island Parachute Jump\nQ: \"Do all of the boards on Riegelmann Boardwalk go the same direction?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c4a0d20dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30329700_d5c1b4620dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30091107_d5c1b4620dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: People in cour Napol\u00e9on, Louvre Museum, Paris 7 June 2000 02\n<image>\nCaption: Louvre Museum Richelieu aisle\nQ: \"Do the fountains in front of the Louvre run both day and night?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c1b4620dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30013399_d5c423140dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30064545_d5c423140dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Big Bus Company LB7739\n<image>\nCaption: Golden Tours bus 110 (BV13 ZDD), 11 May 2013 (2)\nQ: \"Are Golden Tours and The Big Bus Company tour buses predominantly the same color?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c423140dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30341388_d5c52c320dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Bornean orangutan (Pongo pygmaeus), Tanjung Putting National Park 07\nQ: \"Does the bornean orangutan have hair between its nostrils and mouth?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c52c320dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30296313_d5c3524a0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: James R Browning Courthouse Courtroom 1 with Visitor\nQ: \"Are all the chairs in Courtroom 1 in the James R Browning Courthouse in San Francisco of the same type?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3524a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30056160_d5c2f2aa0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 05 Finicky's 02 (186853705)\nQ: \"Does Finicky's have more than one image of a hot dog on their exterior signage?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2f2aa0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30256866_d5c3061e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: John's Inc Fresno\nQ: \"Are the trees near the John's Inc building in Fresno taller than the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3061e0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30284807_d5c31abe0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: VandalRestaurantNYC\nQ: \"Are there lights on both the wall and the ceiling at Vandal Restaurant in New York City?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c31abe0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30042277_d5bfdb4c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Evangelical UCC in Portsmouth\nQ: \"Is the bell of the Evangelical UCC in Portsmouth visible?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bfdb4c0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30377625_d5c40bcc0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Baseball Hall of Fame 2009 2\nQ: \"Does the National Baseball Hall of Fame and Museum in Cooperstown, New York have only one front entrance?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c40bcc0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30043194_d5c307d60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Library Book Drop Box at San Francisco Main Library\nQ: \"Is one allowed to park in front of the drop box at the main San Francisco library?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c307d60dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30299397_d5bebaaa0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30081582_d5bebaaa0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: US Astronaut Hall of Fame\n<image>\nCaption: Rock and Roll Hall of Fame 2003-2\nQ: \"Do the United States Astronaut Hall of Fame and the Rock and Roll Hall of Fame both have square panels on the facade of the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bebaaa0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30114507_d5c02a520dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30201735_d5c02a520dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 2012 Summer Olympics torch relay in Brentford\n<image>\nCaption: Olympic torch relay through Newport\nQ: \"Did only women carry the torch during the 2012 Summer Olympics torch relay?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c02a520dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30048548_d5be76800dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30013130_d5be76800dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Fort Morgan City Hall\n<image>\nCaption: Fort Bragg City Hall\nQ: \"Do both the Fort Morgan City Hall and Fort Bragg City Hall have a set of stairs leading up to their entrance?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5be76800dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30289117_d5c36e060dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 42nd St Bway 7th Av td 25 - Six Times Square Subway\nQ: \"Are people taller than the fence next to the entrance to the Times Square \u2013 42nd Street subway complex next to the Knickerbocker Hotel?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c36e060dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30231011_d5c3bca80dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30370544_d5c3bca80dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Burgerkingrestaurant\n<image>\nCaption: Burger King Restaurant in Sherman Oaks, California - panoramio\nQ: \"Are all Burger King drive thru signs the same height?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3bca80dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30126222_d5c53fec0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Markhor Male and youngs\nQ: \"Are Markhors predominantly white?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c53fec0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30214101_d5c607ce0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30227315_d5c607ce0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Picture of Ruanjian\n<image>\nCaption: Harmony H15 Bobkat\nQ: \"Does a Ruanjian have more strings than a Harmony H15 Bobkat?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c607ce0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30257882_d5bf735a0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30214850_d5bf735a0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Wien, Secession\n<image>\nCaption: Secession Vienna June 2006 019\nQ: \"Does Secession hall keep two plants in pots out front year round?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bf735a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30181539_d5c3493a0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Harvard Stadium aerial axonometric\nQ: \"Is Harvard Stadium taller than a regular bus?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3493a0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30095776_d5c577140dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30031802_d5c577140dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: 131 Kings Road, Brighton (IoE Code 482002)\n<image>\nCaption: 42\u201343 King's Road, Brighton (April 2013)\nQ: \"Do both  the 42\u201343 King's Road building and the 131 King's Road building have handrails on the edge of the roof visible from the front of the building?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c577140dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30169847_d5c420da0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Disney's Art of Animation Resort (7135482003)\nQ: \"Does the ceiling at Disney's Art of Animation Resort make use of the same color scheme as is used on the floor?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c420da0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30215651_d5c3bb720dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30373331_d5c3bb720dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: USA-Santa Barbara-County Courthouse-4\n<image>\nCaption: USA-Santa Barbara-County Courthouse-3\nQ: \"Is the roof type for Santa Barbara County Courthouse is red tiles?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3bb720dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30248722_d5bd151a0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: The Crown Pub, Grafton Street, Brighton\nQ: \"Do both small brown square signs hanging on the side of The Crown Pub, Grafton Street, Brighton have crowns on them?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5bd151a0dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30159293_d5c3806c0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30027115_d5c3806c0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Seuss Landing 03\n<image>\nCaption: Seuss Landing 15\nQ: \"Does the trolley ride at Seuss Landing in Universal's Island of Adventures have a blue track?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3806c0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30180881_d5c3c82e0dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30171371_d5c3c82e0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Jacques-Louis David - Oath of the Horatii - Google Art Project\n<image>\nCaption: David-Oath of the Horatii-1784\nQ: \"Are the women in Jacques Louis David's painting \"Oath of the Horatii standing?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c3c82e0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30231675_d5c2bcd60dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30146577_d5c2bcd60dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Mirage Las Vegas 6 2013-06-24\n<image>\nCaption: The Mirage, Las Vegas (2)\nQ: \"Does The Mirage in Las Vegas have a waterfall outside?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c2bcd60dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30007950_d5c438180dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Seattle (34609780440)\nQ: \"Does Pioneer Square Park have street lights?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c438180dba11ecb1e81171463288e9",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30193227_d5c347fa0dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Despicable Me Minion Mayhem at Universal Studios Japan\nQ: \"Is the Despicable Me: Minion Mayhem main house at Universal Studios Japan taller than the surrounding houses?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c347fa0dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30298260_d5c314740dba11ecb1e81171463288e9.jpeg",
            "/webqa/object_removal/30102297_d5c314740dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Juliana's Pizza, 19 Old Fulton Street, Brooklyn NY\n<image>\nCaption: Parsons Hillside td (2019-03-27) 01 - IND\nQ: \"Do Jennifer's Restaurant and Juliana's Pizza in New York advertise the same type of cuisine on their signs?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c314740dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "/webqa/object_removal/30097593_d5c601c00dba11ecb1e81171463288e9.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nCaption: Washington County Museum of Fine Arts in Hagerstown City Park\nQ: \"Does the Washington County Museum of Fine Arts in Hagerstown City Park have a balustrade running around part of its roof?\""
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "webqa",
        "id": "d5c601c00dba11ecb1e81171463288e9",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1342_1342046.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is sheet music?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1342046",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/263136_263136004.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there any humans here?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "263136004",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/197262_197262003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the white thing in the middle of the pizza?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "197262003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/397523_397523002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this subway car empty?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "397523002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/371638_371638003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What cartoon character is painted on the train?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "371638003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/263351_263351001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Does this woman look happy?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "263351001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1342_1342085.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is showing off that image?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1342085",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/133125_133125000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Would a wedding cake be the same predominant color as this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "133125000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/187695_187695002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of food is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "187695002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/528225_528225012.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Are there flowers?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "528225012",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/3793_3793002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What digital message is the bus displaying?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "3793002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/524535_524535000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Are these chicken eggs?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "524535000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/526723_526723009.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the photo?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "526723009",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/525899_525899001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the photo in black and white?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "525899001",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/4498_4498001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is he about to grind the rail?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "4498001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/546191_546191002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many people are in this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "546191002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/393277_393277001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What's the statue of?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "393277001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/395665_395665001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a man or a woman?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "395665001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/396821_396821003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the water?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "396821003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/527497_527497005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there a door visible in this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "527497005",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/131557_131557001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What topping are on the pizza?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "131557001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/524637_524637002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What shape are the floor tiles?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "524637002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/265153_265153001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the animal?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "265153001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/109992_109992002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many people are outside?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "109992002",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/527064_527064002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this pizza homemade?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "527064002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/393864_393864003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the food half eaten?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "393864003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/526044_526044028.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Can you see a reflection of a cow in the ponds surface?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "526044028",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/136572_136572001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Are there two motorcycles here?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "136572001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/524621_524621018.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of animals are in the dry grass?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "524621018",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/267628_267628005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a major city?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "267628005",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/568191_568191002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the bird?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "568191002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/395113_395113007.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Does this bus take people on tours?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "395113007",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/525665_525665006.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of building are the cows in?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "525665006",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/393984_393984002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is looking at the lady?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "393984002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/526570_526570000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this daytime?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "526570000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/170389_170389003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Are both monitors manufactured by the same company?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "170389003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/396252_396252002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What type of tree is the bird on?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "396252002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/266379_266379007.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the cat wearing a collar?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "266379007",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1525_1525016.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a city?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1525016",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/3501_3501002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there meat in this dish?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "3501002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/415872_415872001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is he a fat man?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "415872001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/397063_397063002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is in his hand?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "397063002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/2985_2985004.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the man riding?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "2985004",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/393274_393274005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there smoke coming out of the train?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "393274005",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/528201_528201002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Does the man enjoy tennis?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "528201002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/398236_398236002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Would a vegan eat this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "398236002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/134213_134213001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this place open at 9 am?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "134213001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/263613_263613001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What animal is in foreground?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "263613001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/397121_397121000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What type of bird is in the photo?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "397121000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/262642_262642002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is this person holding?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "262642002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/136555_136555001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the baby going to a special event?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "136555001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/262800_262800004.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the landing gear of the plane up?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "262800004",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1342_1342075.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the print small?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1342075",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/131617_131617000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the girl in front doing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "131617000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/136624_136624005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the plat?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "136624005",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/536_536001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the blonde lady smiling?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "536001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/546877_546877001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there a canoe in the picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "546877001",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/134199_134199000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Do the elephants look thirsty?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "134199000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/43816_43816027.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the umpire standing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "43816027",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/132415_132415013.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many bites does it look like was taken?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "132415013",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/174989_174989000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a prom or wedding or other similar formal event?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "174989000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/396692_396692010.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this train the first in line?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "396692010",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/394259_394259001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the bowl?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "394259001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/528604_528604019.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Do the two seem comfortable with each other?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "528604019",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/526044_526044015.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the cow looking at?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "526044015",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/132059_132059000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is in the package?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "132059000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/397287_397287001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What material is the sign made of?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "397287001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/528011_528011000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this an Arabian horse?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "528011000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/398537_398537009.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What character is on the umbrella?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "398537009",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1342_1342069.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the last word in the English language sign on the left?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1342069",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/527064_527064001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there meat on this pizza?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "527064001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/133707_133707002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the cat doing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "133707002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/525587_525587002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Will this vehicle leave the area soon?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "525587002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/5282_5282002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many people are in the water?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "5282002",
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/131295_131295005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the title of the person that drives this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "131295005",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/73_73002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What color is the bike?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "73002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/528011_528011001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many sets of tire tracks are in the picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "528011001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/264336_264336002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the bike rider heading East or West?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "264336002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/529404_529404002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is older?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "529404002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/132415_132415024.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How big is this slice of pizza?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "132415024",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/393410_393410010.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What's in the sky?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "393410010",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/262197_262197001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the color of the building in the background?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "262197001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/526028_526028002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a balanced meal?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "526028002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/135673_135673010.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How are the planets different?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "135673010",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/187695_187695001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the white stuff on the food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "187695001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/134811_134811004.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there vegetables on this pizza?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "134811004",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/1342_1342052.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a restaurant?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "1342052",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/776_776002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many bears are there in the picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "776002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/358039_358039008.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this Italian food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "358039008",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/133377_133377001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is he in a barn?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "133377001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/265256_265256002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What flag is the kite styled after?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "265256002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/4256_4256000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there enough bread for two people?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "4256000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/2239_2239005.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a professional tennis player?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "2239005",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/396410_396410001.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many farm animals?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "396410001",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/536_536019.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What are the girls doing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "536019",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/524638_524638000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is there a boy?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "524638000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/136584_136584003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the bird sitting on a branch?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "136584003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/397403_397403000.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the bird sitting on a branch?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "397403000",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/262896_262896003.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is this meal?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "262896003",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "vqa/object_removal/val/396274_396274002.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Are these plants growing in this location naturally or because of human intervention?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "vqa",
        "id": "396274002",
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/340472_3404725.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What do you call the device that keeps boats in place at sea?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3404725,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/147667_1476675.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What does this move have in common with what a waitress does?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1476675,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/306524_3065245.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the tallest of this type of building in the world?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3065245,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/291672_2916725.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What type of boats are those?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2916725,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/523360_5233605.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What product is this advertising?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5233605,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/580757_5807575.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the colorful object used for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5807575,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/184388_1843885.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is famous for allegedly doing this in a lightning storm?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1843885,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/114420_1144205.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the bird in the picture a carnivore or herbivore?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1144205,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/240605_2406055.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What might be the weight of this luggage?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2406055,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/89898_898985.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of trick is that?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 898985,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/45070_450705.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What gait is the horse traveling at?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 450705,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/474711_4747115.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the traditional name for this kind of structure?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4747115,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/575156_5751565.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What event are they planning for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5751565,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/315790_3157905.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the scientific name of the animal on the chair?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3157905,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/526721_5267215.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this animal a carnivore herbivore or omnivore?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5267215,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/462978_4629785.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What animal is on the cup?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4629785,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/333808_3338085.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Name the bird?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3338085,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/396556_3965565.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What food do these animals eat?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3965565,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/542777_5427775.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How is this side dish made?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5427775,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/332351_3323515.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of place is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3323515,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/541664_5416645.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: This display is taken from what famous children's novel?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5416645,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/561314_5613145.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is inside the package?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5613145,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/508748_5087485.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: At what time of day might you eat this kind of food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5087485,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/56736_567365.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of plane is flying?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 567365,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/505891_5058915.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of cat is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5058915,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/115060_1150605.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who invented the mechanical device on this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1150605,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/397890_3978905.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Which person is the groom?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3978905,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/328838_3288385.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How many people are eating these pancakes?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3288385,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/151516_1515165.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the name of the bird in this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1515165,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/360986_3609865.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is a baby cow called?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3609865,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/381318_3813185.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What are the plates made of?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3813185,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/309514_3095145.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Where is this lady having lunch?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3095145,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/179642_1796425.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Can you guess the place where this person is playing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1796425,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/556758_5567585.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of habitat is shown?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5567585,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/326798_3267985.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is this building used for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3267985,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/183217_1832175.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How is this food typically cooked?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1832175,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/274156_2741565.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How heavy is this object?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2741565,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/181873_1818735.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What direction is the skiier going?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1818735,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/308735_3087355.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is a famous chain that might serve this food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3087355,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/59614_596145.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the name of the meal that has these ingredients?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 596145,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/430238_4302385.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What did this organism evolve from?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4302385,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/33131_331315.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who invented this type of device?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 331315,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/428769_4287695.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the make of the vehicle?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4287695,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/388009_3880095.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is another color that this animal is often found in?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3880095,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/275695_2756955.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What would you find in this room?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2756955,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/306383_3063835.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What do these animals eat?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3063835,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/276413_2764135.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is this cake for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2764135,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/188192_1881925.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who owns these three things?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1881925,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/53550_535505.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Would this child be more likely to enjoy a picture book or one with only words?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 535505,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/248297_2482975.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the top speed of these animals?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2482975,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/157192_1571925.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What's the standard ripe color for objects in the picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1571925,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/16606_166065.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What can this be used for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 166065,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/573605_5736055.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What beverage is being served?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5736055,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/408736_4087365.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of cat is this and what are some depictions of this breed of cat in fiction?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4087365,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/407825_4078255.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What breed of animal is on the picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4078255,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/270148_2701485.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the breed of the cat in this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2701485,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/211853_2118535.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What fuel does this take?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2118535,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/329494_3294945.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How tall are these animals?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3294945,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/428452_4284525.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the pink food in the sandwich?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4284525,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/242513_2425135.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What rails does this vehicle drive on?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2425135,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/113271_1132715.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of dog is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1132715,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/345380_3453805.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How high can this animal jump?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3453805,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/30967_309675.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Which feline has a pelt similar to this animals but with smaller detailing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 309675,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/187745_1877455.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: When was the first airplane flight?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1877455,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/187244_1872445.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is a famous american athlete that engages in this type of sport?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1872445,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/74798_747985.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What bird is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 747985,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/225721_2257215.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is this a scientist or drug addict?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2257215,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/325114_3251145.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Would you use a broom or a mop to clean this room?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3251145,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/292819_2928195.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: The wire filaments inside the rubber wheel are called what?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2928195,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/91751_917515.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the player most likely kicking the ball towards?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 917515,
        "label": false
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/335427_3354275.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is in the bowl with the broccoli?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3354275,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/544590_5445905.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is the name for this creatures offspring?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5445905,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/315810_3158105.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What type of hit is being preformed?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3158105,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/80194_801945.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What type of net is used to play this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 801945,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/108208_1082085.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What culture do you believe made this food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1082085,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/331816_3318165.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of fabric product is produced from these animals?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3318165,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/323418_3234185.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What types of planes are these?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3234185,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/274708_2747085.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is scary about this photo?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2747085,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/54358_543585.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What religion uses the floor mat and pillow like this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 543585,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/104119_1041195.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: On what holiday do people traditionally eat this bird?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1041195,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/536183_5361835.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What food is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5361835,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/275020_2750205.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How do you make this food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2750205,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/295589_2955895.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who is the official in this sport?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2955895,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/127781_1277815.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Why is this cat under the umbrella?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1277815,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/97994_979945.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What brand soda is on the desk?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 979945,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/211163_2111635.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What team does he play for?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2111635,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/535997_5359975.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What city is this in?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5359975,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/393145_3931455.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Is the relationship between these two animals good or bad?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 3931455,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/76588_765885.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What breed of cat is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 765885,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/215424_2154245.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Who should eat this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2154245,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/501047_5010475.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What is this animal doing?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 5010475,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/213457_2134575.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: From what source does the yellow glean on the snow come from?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2134575,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/460732_4607325.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Name the place where the monkey is sitting in this picture?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4607325,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/236162_2361625.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: Batman's main female villain surround herself with these?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 2361625,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/147745_1477455.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What attaches behind these objects?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1477455,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/94336_943365.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What breed of cat is this?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 943365,
        "label": true
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/119308_1193085.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How did this boy get in the air?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1193085
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/142564_1425645.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: How often should children do what is shown in this photo?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1425645
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/139248_1392485.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What kind of activity is this person engaged in?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 1392485
    },
    {
        "system_prompt": "Answer the question Q. If you need help answer <RET> to get the context.",
        "image": [
            "okvqa/object_removal/val/430002_4300025.jpeg"
        ],
        "conversations": [
            {
                "from": "human",
                "value": "<image>\nQ: What other types of portable objects are made from the material of the tray under the food?"
            },
            {
                "from": "gpt",
                "value": "<RET> Sorry, I cannot determine the answer as there is not enough information. <RET>"
            }
        ],
        "type": "counterfactual",
        "dataset": "okvqa",
        "id": 4300025
    }
]